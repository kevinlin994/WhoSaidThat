{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n",
      "/home/ubuntu/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n",
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.metrics import classification_report,accuracy_score, roc_auc_score, roc_curve, auc\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import metrics\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "import tensorflow as tf\n",
    "# from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try:\n",
    "#     metrics_df = pd.read_csv('Modeling_Results')\n",
    "# except:\n",
    "metrics_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Returns a dictionary of metrics for each algorithm\n",
    "def metrics_to_dict(algorithm, y_test, y_pred, train_acc, params):\n",
    "    results = {}\n",
    "    prec = metrics.precision_score(y_test, y_pred)\n",
    "    accuracy = metrics.accuracy_score(y_pred, y_test)\n",
    "    recall = metrics.recall_score(y_test,y_pred)\n",
    "    f1 = metrics.f1_score(y_test,y_pred)\n",
    "    results['Algorithm'] = algorithm\n",
    "    results['Train Accuracy'] = train_acc\n",
    "    results['Hold Out Accuracy'] = accuracy\n",
    "    results['Precision'] = prec\n",
    "    results['Recall'] = recall\n",
    "    results['F1 Score'] = f1\n",
    "    results['Parameters'] = [params]\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fft = pd.read_csv('full_dataset_sex')\n",
    "# df_features = pd.read_csv('subset_df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fft.drop(columns=['Unnamed: 0', 'Unnamed: 0.1'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['0', '1', '2', '3', '4', '5', '6', '7', '8', '9',\n",
       "       ...\n",
       "       '183', '184', '185', '186', '187', '188', '189', 'Gender', 'ID', 'Sex'],\n",
       "      dtype='object', length=193)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fft.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-0e77441ef3a8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_fft\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df_features' is not defined"
     ]
    }
   ],
   "source": [
    "len(df_fft) == len(df_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_metrics' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-82e9eed8a4f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_metrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Unnamed: 0'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'index'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df_metrics' is not defined"
     ]
    }
   ],
   "source": [
    "df_metrics.drop(columns=['Unnamed: 0', 'index'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Spectral_Centroid</th>\n",
       "      <th>Spectral_Centroid_std</th>\n",
       "      <th>Skew</th>\n",
       "      <th>Kurtosis</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>RMSE_std</th>\n",
       "      <th>Spectral_rolloff</th>\n",
       "      <th>Tempo</th>\n",
       "      <th>mfcc_1</th>\n",
       "      <th>mfcc_2</th>\n",
       "      <th>mfcc_3</th>\n",
       "      <th>Zero_Crossing_Rate</th>\n",
       "      <th>Zero_Crossing_std</th>\n",
       "      <th>Gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1914.418019</td>\n",
       "      <td>717.910164</td>\n",
       "      <td>1.407838</td>\n",
       "      <td>9.192312</td>\n",
       "      <td>2.505518</td>\n",
       "      <td>1.818305</td>\n",
       "      <td>4868.640137</td>\n",
       "      <td>142.635942</td>\n",
       "      <td>-115.756918</td>\n",
       "      <td>120.148548</td>\n",
       "      <td>-23.335506</td>\n",
       "      <td>0.156591</td>\n",
       "      <td>0.086763</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Spectral_Centroid  Spectral_Centroid_std      Skew  Kurtosis  \\\n",
       "0           0        1914.418019             717.910164  1.407838  9.192312   \n",
       "\n",
       "       RMSE  RMSE_std  Spectral_rolloff       Tempo      mfcc_1      mfcc_2  \\\n",
       "0  2.505518  1.818305       4868.640137  142.635942 -115.756918  120.148548   \n",
       "\n",
       "      mfcc_3  Zero_Crossing_Rate  Zero_Crossing_std Gender  \n",
       "0 -23.335506            0.156591           0.086763      m  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_features.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_fft['Sex'] = [1 if x == 'm' else 0 for x in df_fft['Gender']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>182</th>\n",
       "      <th>183</th>\n",
       "      <th>184</th>\n",
       "      <th>185</th>\n",
       "      <th>186</th>\n",
       "      <th>187</th>\n",
       "      <th>188</th>\n",
       "      <th>189</th>\n",
       "      <th>Gender</th>\n",
       "      <th>ID</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>333793</td>\n",
       "      <td>333793</td>\n",
       "      <td>333793</td>\n",
       "      <td>333793</td>\n",
       "      <td>333793</td>\n",
       "      <td>333793</td>\n",
       "      <td>333793</td>\n",
       "      <td>333793</td>\n",
       "      <td>333793</td>\n",
       "      <td>333793</td>\n",
       "      <td>...</td>\n",
       "      <td>333793</td>\n",
       "      <td>333793</td>\n",
       "      <td>333793</td>\n",
       "      <td>333793</td>\n",
       "      <td>333793</td>\n",
       "      <td>333793</td>\n",
       "      <td>333793</td>\n",
       "      <td>333793</td>\n",
       "      <td>333793</td>\n",
       "      <td>333793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>265548</td>\n",
       "      <td>265548</td>\n",
       "      <td>265548</td>\n",
       "      <td>265548</td>\n",
       "      <td>265548</td>\n",
       "      <td>265548</td>\n",
       "      <td>265548</td>\n",
       "      <td>265548</td>\n",
       "      <td>265548</td>\n",
       "      <td>265548</td>\n",
       "      <td>...</td>\n",
       "      <td>265548</td>\n",
       "      <td>265548</td>\n",
       "      <td>265548</td>\n",
       "      <td>265548</td>\n",
       "      <td>265548</td>\n",
       "      <td>265548</td>\n",
       "      <td>265548</td>\n",
       "      <td>265548</td>\n",
       "      <td>265548</td>\n",
       "      <td>265548</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 192 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0       1       2       3       4       5       6       7       8  \\\n",
       "Sex                                                                           \n",
       "0    333793  333793  333793  333793  333793  333793  333793  333793  333793   \n",
       "1    265548  265548  265548  265548  265548  265548  265548  265548  265548   \n",
       "\n",
       "          9   ...       182     183     184     185     186     187     188  \\\n",
       "Sex           ...                                                             \n",
       "0    333793   ...    333793  333793  333793  333793  333793  333793  333793   \n",
       "1    265548   ...    265548  265548  265548  265548  265548  265548  265548   \n",
       "\n",
       "        189  Gender      ID  \n",
       "Sex                          \n",
       "0    333793  333793  333793  \n",
       "1    265548  265548  265548  \n",
       "\n",
       "[2 rows x 192 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fft.groupby('Sex').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.360202438463308"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "140922/(140922+250308)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['0', '1', '2', '3', '4', '5', '6', '7', '8', '9',\n",
       "       ...\n",
       "       '180', '181', '182', '183', '184', '185', '186', '187', '188', '189'],\n",
       "      dtype='object', length=190)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fft.iloc[:,:190].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mean_3 = df_fft.groupby('ID').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Cannot access callable attribute 'groupby' of 'DataFrameGroupBy' objects, try using the 'apply' method",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-70be9657582a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_mean_3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_mean_3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ID'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/groupby.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m    671\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mattr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 673\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m         raise AttributeError(\"%r object has no attribute %r\" %\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/groupby.py\u001b[0m in \u001b[0;36m_make_wrapper\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    685\u001b[0m                    \"using the 'apply' method\".format(kind, name,\n\u001b[1;32m    686\u001b[0m                                                      type(self).__name__))\n\u001b[0;32m--> 687\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    689\u001b[0m         \u001b[0;31m# need to setup the selection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: Cannot access callable attribute 'groupby' of 'DataFrameGroupBy' objects, try using the 'apply' method"
     ]
    }
   ],
   "source": [
    "df_mean_3 = df_mean_3.groupby('ID').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>180</th>\n",
       "      <th>181</th>\n",
       "      <th>182</th>\n",
       "      <th>183</th>\n",
       "      <th>184</th>\n",
       "      <th>185</th>\n",
       "      <th>186</th>\n",
       "      <th>187</th>\n",
       "      <th>188</th>\n",
       "      <th>189</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1940</td>\n",
       "      <td>1940</td>\n",
       "      <td>1940</td>\n",
       "      <td>1940</td>\n",
       "      <td>1940</td>\n",
       "      <td>1940</td>\n",
       "      <td>1940</td>\n",
       "      <td>1940</td>\n",
       "      <td>1940</td>\n",
       "      <td>1940</td>\n",
       "      <td>...</td>\n",
       "      <td>1940</td>\n",
       "      <td>1940</td>\n",
       "      <td>1940</td>\n",
       "      <td>1940</td>\n",
       "      <td>1940</td>\n",
       "      <td>1940</td>\n",
       "      <td>1940</td>\n",
       "      <td>1940</td>\n",
       "      <td>1940</td>\n",
       "      <td>1940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3019</td>\n",
       "      <td>3019</td>\n",
       "      <td>3019</td>\n",
       "      <td>3019</td>\n",
       "      <td>3019</td>\n",
       "      <td>3019</td>\n",
       "      <td>3019</td>\n",
       "      <td>3019</td>\n",
       "      <td>3019</td>\n",
       "      <td>3019</td>\n",
       "      <td>...</td>\n",
       "      <td>3019</td>\n",
       "      <td>3019</td>\n",
       "      <td>3019</td>\n",
       "      <td>3019</td>\n",
       "      <td>3019</td>\n",
       "      <td>3019</td>\n",
       "      <td>3019</td>\n",
       "      <td>3019</td>\n",
       "      <td>3019</td>\n",
       "      <td>3019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 190 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0     1     2     3     4     5     6     7     8     9  ...    180  \\\n",
       "Sex                                                              ...          \n",
       "0    1940  1940  1940  1940  1940  1940  1940  1940  1940  1940  ...   1940   \n",
       "1    3019  3019  3019  3019  3019  3019  3019  3019  3019  3019  ...   3019   \n",
       "\n",
       "      181   182   183   184   185   186   187   188   189  \n",
       "Sex                                                        \n",
       "0    1940  1940  1940  1940  1940  1940  1940  1940  1940  \n",
       "1    3019  3019  3019  3019  3019  3019  3019  3019  3019  \n",
       "\n",
       "[2 rows x 190 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mean_3.groupby('Sex').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>181</th>\n",
       "      <th>182</th>\n",
       "      <th>183</th>\n",
       "      <th>184</th>\n",
       "      <th>185</th>\n",
       "      <th>186</th>\n",
       "      <th>187</th>\n",
       "      <th>188</th>\n",
       "      <th>189</th>\n",
       "      <th>Sex</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id00012</th>\n",
       "      <td>2.666514</td>\n",
       "      <td>1.736939</td>\n",
       "      <td>1.158345</td>\n",
       "      <td>1.790269</td>\n",
       "      <td>2.128618</td>\n",
       "      <td>1.917723</td>\n",
       "      <td>1.524069</td>\n",
       "      <td>4.657731</td>\n",
       "      <td>1.383169</td>\n",
       "      <td>3.673608</td>\n",
       "      <td>...</td>\n",
       "      <td>2.444855</td>\n",
       "      <td>2.127628</td>\n",
       "      <td>2.109255</td>\n",
       "      <td>3.181896</td>\n",
       "      <td>2.111263</td>\n",
       "      <td>2.259769</td>\n",
       "      <td>1.353609</td>\n",
       "      <td>2.217303</td>\n",
       "      <td>4.026561</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id00018</th>\n",
       "      <td>3.866567</td>\n",
       "      <td>3.308477</td>\n",
       "      <td>2.099306</td>\n",
       "      <td>1.620708</td>\n",
       "      <td>2.995494</td>\n",
       "      <td>1.519316</td>\n",
       "      <td>3.004626</td>\n",
       "      <td>1.265518</td>\n",
       "      <td>2.483844</td>\n",
       "      <td>3.510914</td>\n",
       "      <td>...</td>\n",
       "      <td>16.853714</td>\n",
       "      <td>22.786992</td>\n",
       "      <td>10.819950</td>\n",
       "      <td>12.771045</td>\n",
       "      <td>25.415175</td>\n",
       "      <td>14.065540</td>\n",
       "      <td>18.978004</td>\n",
       "      <td>19.324807</td>\n",
       "      <td>14.908907</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id00019</th>\n",
       "      <td>0.980058</td>\n",
       "      <td>1.837420</td>\n",
       "      <td>1.152202</td>\n",
       "      <td>1.165895</td>\n",
       "      <td>1.816326</td>\n",
       "      <td>1.333596</td>\n",
       "      <td>0.929478</td>\n",
       "      <td>1.197637</td>\n",
       "      <td>1.589045</td>\n",
       "      <td>2.073400</td>\n",
       "      <td>...</td>\n",
       "      <td>22.754171</td>\n",
       "      <td>19.628845</td>\n",
       "      <td>23.227182</td>\n",
       "      <td>10.786076</td>\n",
       "      <td>24.588652</td>\n",
       "      <td>15.593162</td>\n",
       "      <td>14.239353</td>\n",
       "      <td>23.147509</td>\n",
       "      <td>12.935843</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id00020</th>\n",
       "      <td>2.470025</td>\n",
       "      <td>2.683406</td>\n",
       "      <td>1.566433</td>\n",
       "      <td>1.576143</td>\n",
       "      <td>2.716434</td>\n",
       "      <td>5.700669</td>\n",
       "      <td>3.974343</td>\n",
       "      <td>5.858382</td>\n",
       "      <td>3.004119</td>\n",
       "      <td>6.376210</td>\n",
       "      <td>...</td>\n",
       "      <td>8.265149</td>\n",
       "      <td>7.629799</td>\n",
       "      <td>7.695075</td>\n",
       "      <td>3.251242</td>\n",
       "      <td>4.987161</td>\n",
       "      <td>6.515693</td>\n",
       "      <td>5.976787</td>\n",
       "      <td>4.146975</td>\n",
       "      <td>6.702565</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id00022</th>\n",
       "      <td>8.510809</td>\n",
       "      <td>4.013943</td>\n",
       "      <td>10.465756</td>\n",
       "      <td>14.430515</td>\n",
       "      <td>14.115017</td>\n",
       "      <td>15.512525</td>\n",
       "      <td>18.147178</td>\n",
       "      <td>10.152281</td>\n",
       "      <td>7.566912</td>\n",
       "      <td>10.432986</td>\n",
       "      <td>...</td>\n",
       "      <td>6.530424</td>\n",
       "      <td>5.774186</td>\n",
       "      <td>7.149016</td>\n",
       "      <td>5.980288</td>\n",
       "      <td>6.341032</td>\n",
       "      <td>5.824727</td>\n",
       "      <td>8.058199</td>\n",
       "      <td>6.044662</td>\n",
       "      <td>11.776013</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id00024</th>\n",
       "      <td>0.562785</td>\n",
       "      <td>0.462425</td>\n",
       "      <td>0.741593</td>\n",
       "      <td>0.578841</td>\n",
       "      <td>1.046791</td>\n",
       "      <td>1.025440</td>\n",
       "      <td>1.032807</td>\n",
       "      <td>0.877103</td>\n",
       "      <td>0.832526</td>\n",
       "      <td>1.622779</td>\n",
       "      <td>...</td>\n",
       "      <td>37.557951</td>\n",
       "      <td>11.946116</td>\n",
       "      <td>22.955237</td>\n",
       "      <td>36.019117</td>\n",
       "      <td>21.584943</td>\n",
       "      <td>6.990265</td>\n",
       "      <td>14.425140</td>\n",
       "      <td>19.600922</td>\n",
       "      <td>16.230263</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id00025</th>\n",
       "      <td>0.153742</td>\n",
       "      <td>0.175582</td>\n",
       "      <td>0.265045</td>\n",
       "      <td>0.241335</td>\n",
       "      <td>0.159157</td>\n",
       "      <td>0.322375</td>\n",
       "      <td>0.322586</td>\n",
       "      <td>0.456646</td>\n",
       "      <td>0.245129</td>\n",
       "      <td>0.319397</td>\n",
       "      <td>...</td>\n",
       "      <td>8.172353</td>\n",
       "      <td>5.372250</td>\n",
       "      <td>5.221166</td>\n",
       "      <td>6.090531</td>\n",
       "      <td>4.805570</td>\n",
       "      <td>4.058229</td>\n",
       "      <td>3.893476</td>\n",
       "      <td>2.855270</td>\n",
       "      <td>1.911586</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id00026</th>\n",
       "      <td>1.130349</td>\n",
       "      <td>1.061265</td>\n",
       "      <td>1.191811</td>\n",
       "      <td>1.646337</td>\n",
       "      <td>2.395768</td>\n",
       "      <td>0.817556</td>\n",
       "      <td>1.597435</td>\n",
       "      <td>1.676377</td>\n",
       "      <td>1.178263</td>\n",
       "      <td>1.578277</td>\n",
       "      <td>...</td>\n",
       "      <td>28.167205</td>\n",
       "      <td>28.936205</td>\n",
       "      <td>25.966203</td>\n",
       "      <td>25.165950</td>\n",
       "      <td>19.824578</td>\n",
       "      <td>28.227274</td>\n",
       "      <td>17.603077</td>\n",
       "      <td>21.637453</td>\n",
       "      <td>22.866847</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id00027</th>\n",
       "      <td>2.323866</td>\n",
       "      <td>1.204467</td>\n",
       "      <td>1.469019</td>\n",
       "      <td>1.509376</td>\n",
       "      <td>2.343780</td>\n",
       "      <td>2.108433</td>\n",
       "      <td>1.045771</td>\n",
       "      <td>2.714258</td>\n",
       "      <td>1.079049</td>\n",
       "      <td>1.604778</td>\n",
       "      <td>...</td>\n",
       "      <td>21.137971</td>\n",
       "      <td>14.969207</td>\n",
       "      <td>13.792308</td>\n",
       "      <td>15.594114</td>\n",
       "      <td>10.566836</td>\n",
       "      <td>25.369816</td>\n",
       "      <td>28.334713</td>\n",
       "      <td>29.244976</td>\n",
       "      <td>25.269735</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id00028</th>\n",
       "      <td>3.035594</td>\n",
       "      <td>2.147924</td>\n",
       "      <td>1.817727</td>\n",
       "      <td>2.678931</td>\n",
       "      <td>2.041058</td>\n",
       "      <td>2.174266</td>\n",
       "      <td>3.932939</td>\n",
       "      <td>2.096481</td>\n",
       "      <td>1.500588</td>\n",
       "      <td>1.898173</td>\n",
       "      <td>...</td>\n",
       "      <td>7.816985</td>\n",
       "      <td>8.352660</td>\n",
       "      <td>10.500431</td>\n",
       "      <td>10.447789</td>\n",
       "      <td>5.659825</td>\n",
       "      <td>9.092096</td>\n",
       "      <td>12.999733</td>\n",
       "      <td>4.316463</td>\n",
       "      <td>8.383385</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id00029</th>\n",
       "      <td>2.132380</td>\n",
       "      <td>1.190861</td>\n",
       "      <td>0.813621</td>\n",
       "      <td>1.982442</td>\n",
       "      <td>2.653803</td>\n",
       "      <td>2.724420</td>\n",
       "      <td>4.109868</td>\n",
       "      <td>1.467896</td>\n",
       "      <td>5.525037</td>\n",
       "      <td>2.591005</td>\n",
       "      <td>...</td>\n",
       "      <td>30.130817</td>\n",
       "      <td>15.017449</td>\n",
       "      <td>19.411332</td>\n",
       "      <td>21.692557</td>\n",
       "      <td>15.602820</td>\n",
       "      <td>12.881429</td>\n",
       "      <td>16.821884</td>\n",
       "      <td>14.993693</td>\n",
       "      <td>21.802091</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id00032</th>\n",
       "      <td>4.062975</td>\n",
       "      <td>3.532017</td>\n",
       "      <td>4.333744</td>\n",
       "      <td>4.780152</td>\n",
       "      <td>2.476107</td>\n",
       "      <td>4.024173</td>\n",
       "      <td>3.684624</td>\n",
       "      <td>4.362876</td>\n",
       "      <td>1.364309</td>\n",
       "      <td>2.257892</td>\n",
       "      <td>...</td>\n",
       "      <td>14.400048</td>\n",
       "      <td>8.826859</td>\n",
       "      <td>4.613547</td>\n",
       "      <td>6.786347</td>\n",
       "      <td>6.959559</td>\n",
       "      <td>3.976563</td>\n",
       "      <td>6.482851</td>\n",
       "      <td>7.695543</td>\n",
       "      <td>1.695017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id00033</th>\n",
       "      <td>2.387803</td>\n",
       "      <td>2.062441</td>\n",
       "      <td>1.853585</td>\n",
       "      <td>2.418103</td>\n",
       "      <td>2.013974</td>\n",
       "      <td>1.816602</td>\n",
       "      <td>3.007126</td>\n",
       "      <td>3.032722</td>\n",
       "      <td>2.102787</td>\n",
       "      <td>3.284746</td>\n",
       "      <td>...</td>\n",
       "      <td>20.290933</td>\n",
       "      <td>13.709683</td>\n",
       "      <td>16.740742</td>\n",
       "      <td>14.657354</td>\n",
       "      <td>15.698034</td>\n",
       "      <td>20.802737</td>\n",
       "      <td>12.250548</td>\n",
       "      <td>14.791108</td>\n",
       "      <td>10.808265</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id00035</th>\n",
       "      <td>0.726346</td>\n",
       "      <td>0.917897</td>\n",
       "      <td>0.723405</td>\n",
       "      <td>0.707427</td>\n",
       "      <td>0.812177</td>\n",
       "      <td>1.142542</td>\n",
       "      <td>1.031773</td>\n",
       "      <td>1.240735</td>\n",
       "      <td>1.070356</td>\n",
       "      <td>0.923115</td>\n",
       "      <td>...</td>\n",
       "      <td>11.733148</td>\n",
       "      <td>22.343121</td>\n",
       "      <td>17.423413</td>\n",
       "      <td>16.616798</td>\n",
       "      <td>11.894639</td>\n",
       "      <td>19.319168</td>\n",
       "      <td>15.578912</td>\n",
       "      <td>7.052004</td>\n",
       "      <td>6.677454</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id00036</th>\n",
       "      <td>7.323147</td>\n",
       "      <td>12.031888</td>\n",
       "      <td>13.678829</td>\n",
       "      <td>4.984016</td>\n",
       "      <td>6.831900</td>\n",
       "      <td>3.963119</td>\n",
       "      <td>7.436767</td>\n",
       "      <td>6.448851</td>\n",
       "      <td>9.539648</td>\n",
       "      <td>12.746929</td>\n",
       "      <td>...</td>\n",
       "      <td>9.030141</td>\n",
       "      <td>5.529461</td>\n",
       "      <td>8.289636</td>\n",
       "      <td>23.512148</td>\n",
       "      <td>29.349329</td>\n",
       "      <td>10.607384</td>\n",
       "      <td>15.829012</td>\n",
       "      <td>25.250293</td>\n",
       "      <td>18.017826</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id00039</th>\n",
       "      <td>9.507171</td>\n",
       "      <td>4.851099</td>\n",
       "      <td>6.765448</td>\n",
       "      <td>7.961253</td>\n",
       "      <td>5.164460</td>\n",
       "      <td>6.878731</td>\n",
       "      <td>3.940919</td>\n",
       "      <td>6.018472</td>\n",
       "      <td>4.569367</td>\n",
       "      <td>4.712691</td>\n",
       "      <td>...</td>\n",
       "      <td>27.180280</td>\n",
       "      <td>22.255941</td>\n",
       "      <td>21.116806</td>\n",
       "      <td>18.541870</td>\n",
       "      <td>10.345109</td>\n",
       "      <td>15.615980</td>\n",
       "      <td>15.188607</td>\n",
       "      <td>25.551843</td>\n",
       "      <td>31.692928</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id00040</th>\n",
       "      <td>1.268790</td>\n",
       "      <td>0.941258</td>\n",
       "      <td>1.709855</td>\n",
       "      <td>1.393628</td>\n",
       "      <td>1.715932</td>\n",
       "      <td>1.431332</td>\n",
       "      <td>1.583902</td>\n",
       "      <td>1.862646</td>\n",
       "      <td>1.582926</td>\n",
       "      <td>1.566749</td>\n",
       "      <td>...</td>\n",
       "      <td>16.507210</td>\n",
       "      <td>17.890345</td>\n",
       "      <td>12.408214</td>\n",
       "      <td>14.521081</td>\n",
       "      <td>20.119526</td>\n",
       "      <td>10.133350</td>\n",
       "      <td>14.512740</td>\n",
       "      <td>10.095722</td>\n",
       "      <td>7.234862</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id00042</th>\n",
       "      <td>7.013058</td>\n",
       "      <td>29.560124</td>\n",
       "      <td>24.166933</td>\n",
       "      <td>23.341047</td>\n",
       "      <td>14.778809</td>\n",
       "      <td>31.705640</td>\n",
       "      <td>6.522730</td>\n",
       "      <td>17.037722</td>\n",
       "      <td>18.025191</td>\n",
       "      <td>7.575657</td>\n",
       "      <td>...</td>\n",
       "      <td>151.733320</td>\n",
       "      <td>74.755521</td>\n",
       "      <td>101.662205</td>\n",
       "      <td>124.714312</td>\n",
       "      <td>149.425271</td>\n",
       "      <td>142.791953</td>\n",
       "      <td>131.193774</td>\n",
       "      <td>116.496717</td>\n",
       "      <td>117.210467</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id00043</th>\n",
       "      <td>1.083236</td>\n",
       "      <td>0.709477</td>\n",
       "      <td>0.230486</td>\n",
       "      <td>0.431884</td>\n",
       "      <td>1.058905</td>\n",
       "      <td>0.697872</td>\n",
       "      <td>0.933384</td>\n",
       "      <td>0.927028</td>\n",
       "      <td>1.029810</td>\n",
       "      <td>0.758568</td>\n",
       "      <td>...</td>\n",
       "      <td>19.443915</td>\n",
       "      <td>20.111314</td>\n",
       "      <td>23.573624</td>\n",
       "      <td>25.235381</td>\n",
       "      <td>31.427178</td>\n",
       "      <td>24.909478</td>\n",
       "      <td>23.064022</td>\n",
       "      <td>19.682376</td>\n",
       "      <td>23.819299</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id00044</th>\n",
       "      <td>2.328791</td>\n",
       "      <td>5.229773</td>\n",
       "      <td>4.376595</td>\n",
       "      <td>4.972605</td>\n",
       "      <td>3.817128</td>\n",
       "      <td>6.408254</td>\n",
       "      <td>4.726422</td>\n",
       "      <td>3.700584</td>\n",
       "      <td>2.582421</td>\n",
       "      <td>1.966189</td>\n",
       "      <td>...</td>\n",
       "      <td>8.558032</td>\n",
       "      <td>8.117445</td>\n",
       "      <td>7.023194</td>\n",
       "      <td>12.667714</td>\n",
       "      <td>15.671313</td>\n",
       "      <td>18.162131</td>\n",
       "      <td>18.242509</td>\n",
       "      <td>16.818772</td>\n",
       "      <td>17.791680</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id00047</th>\n",
       "      <td>2.630139</td>\n",
       "      <td>3.704673</td>\n",
       "      <td>2.406458</td>\n",
       "      <td>3.505847</td>\n",
       "      <td>2.259006</td>\n",
       "      <td>3.479831</td>\n",
       "      <td>4.203078</td>\n",
       "      <td>4.996240</td>\n",
       "      <td>3.384179</td>\n",
       "      <td>3.526166</td>\n",
       "      <td>...</td>\n",
       "      <td>23.115702</td>\n",
       "      <td>23.884573</td>\n",
       "      <td>24.580932</td>\n",
       "      <td>18.925946</td>\n",
       "      <td>22.296105</td>\n",
       "      <td>13.982835</td>\n",
       "      <td>16.442029</td>\n",
       "      <td>30.591993</td>\n",
       "      <td>31.528857</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id00049</th>\n",
       "      <td>5.060342</td>\n",
       "      <td>6.103115</td>\n",
       "      <td>10.074891</td>\n",
       "      <td>5.898734</td>\n",
       "      <td>5.529209</td>\n",
       "      <td>12.751007</td>\n",
       "      <td>6.974557</td>\n",
       "      <td>6.293443</td>\n",
       "      <td>8.945688</td>\n",
       "      <td>6.715341</td>\n",
       "      <td>...</td>\n",
       "      <td>8.755644</td>\n",
       "      <td>3.048386</td>\n",
       "      <td>4.314952</td>\n",
       "      <td>5.001781</td>\n",
       "      <td>8.758627</td>\n",
       "      <td>8.887190</td>\n",
       "      <td>9.018789</td>\n",
       "      <td>8.592075</td>\n",
       "      <td>10.045943</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id00051</th>\n",
       "      <td>28.949994</td>\n",
       "      <td>38.374034</td>\n",
       "      <td>24.113973</td>\n",
       "      <td>28.754525</td>\n",
       "      <td>27.823202</td>\n",
       "      <td>30.088761</td>\n",
       "      <td>59.844800</td>\n",
       "      <td>33.248550</td>\n",
       "      <td>54.488929</td>\n",
       "      <td>35.329123</td>\n",
       "      <td>...</td>\n",
       "      <td>142.136361</td>\n",
       "      <td>142.157074</td>\n",
       "      <td>120.014727</td>\n",
       "      <td>94.835124</td>\n",
       "      <td>191.868755</td>\n",
       "      <td>206.279904</td>\n",
       "      <td>115.553566</td>\n",
       "      <td>62.789704</td>\n",
       "      <td>130.137807</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id00052</th>\n",
       "      <td>0.574329</td>\n",
       "      <td>0.472937</td>\n",
       "      <td>0.770717</td>\n",
       "      <td>0.547800</td>\n",
       "      <td>0.586500</td>\n",
       "      <td>0.392446</td>\n",
       "      <td>0.805393</td>\n",
       "      <td>0.589383</td>\n",
       "      <td>0.261549</td>\n",
       "      <td>0.675292</td>\n",
       "      <td>...</td>\n",
       "      <td>3.074363</td>\n",
       "      <td>3.281674</td>\n",
       "      <td>3.834960</td>\n",
       "      <td>5.002620</td>\n",
       "      <td>7.024471</td>\n",
       "      <td>4.164413</td>\n",
       "      <td>7.245253</td>\n",
       "      <td>4.246504</td>\n",
       "      <td>4.010246</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id00053</th>\n",
       "      <td>5.998414</td>\n",
       "      <td>3.995160</td>\n",
       "      <td>4.467448</td>\n",
       "      <td>5.241607</td>\n",
       "      <td>4.290500</td>\n",
       "      <td>6.095347</td>\n",
       "      <td>1.928679</td>\n",
       "      <td>7.316389</td>\n",
       "      <td>2.999429</td>\n",
       "      <td>8.383681</td>\n",
       "      <td>...</td>\n",
       "      <td>10.526931</td>\n",
       "      <td>6.975480</td>\n",
       "      <td>4.859496</td>\n",
       "      <td>7.349589</td>\n",
       "      <td>3.780885</td>\n",
       "      <td>12.557552</td>\n",
       "      <td>12.916443</td>\n",
       "      <td>16.294392</td>\n",
       "      <td>11.336656</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id00055</th>\n",
       "      <td>0.413586</td>\n",
       "      <td>0.987610</td>\n",
       "      <td>0.683441</td>\n",
       "      <td>0.471844</td>\n",
       "      <td>0.867311</td>\n",
       "      <td>1.675066</td>\n",
       "      <td>1.534770</td>\n",
       "      <td>1.219493</td>\n",
       "      <td>2.195528</td>\n",
       "      <td>1.815940</td>\n",
       "      <td>...</td>\n",
       "      <td>3.423476</td>\n",
       "      <td>2.593513</td>\n",
       "      <td>3.140839</td>\n",
       "      <td>3.679644</td>\n",
       "      <td>3.378531</td>\n",
       "      <td>0.953940</td>\n",
       "      <td>2.112174</td>\n",
       "      <td>3.131860</td>\n",
       "      <td>2.405244</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id00056</th>\n",
       "      <td>5.348130</td>\n",
       "      <td>6.387375</td>\n",
       "      <td>8.161529</td>\n",
       "      <td>7.274211</td>\n",
       "      <td>4.859745</td>\n",
       "      <td>5.255259</td>\n",
       "      <td>5.442443</td>\n",
       "      <td>4.761402</td>\n",
       "      <td>2.743283</td>\n",
       "      <td>4.591072</td>\n",
       "      <td>...</td>\n",
       "      <td>11.123622</td>\n",
       "      <td>7.105595</td>\n",
       "      <td>7.765454</td>\n",
       "      <td>9.896080</td>\n",
       "      <td>3.701304</td>\n",
       "      <td>9.744414</td>\n",
       "      <td>3.856813</td>\n",
       "      <td>8.135829</td>\n",
       "      <td>6.221934</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id00058</th>\n",
       "      <td>0.701271</td>\n",
       "      <td>1.360822</td>\n",
       "      <td>1.250774</td>\n",
       "      <td>0.995929</td>\n",
       "      <td>1.221501</td>\n",
       "      <td>1.772693</td>\n",
       "      <td>0.953341</td>\n",
       "      <td>0.957259</td>\n",
       "      <td>1.798072</td>\n",
       "      <td>1.544146</td>\n",
       "      <td>...</td>\n",
       "      <td>17.031646</td>\n",
       "      <td>23.497007</td>\n",
       "      <td>13.849762</td>\n",
       "      <td>27.339371</td>\n",
       "      <td>29.412244</td>\n",
       "      <td>32.002158</td>\n",
       "      <td>23.609476</td>\n",
       "      <td>25.127126</td>\n",
       "      <td>26.966707</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id00059</th>\n",
       "      <td>19.545645</td>\n",
       "      <td>8.438138</td>\n",
       "      <td>6.780867</td>\n",
       "      <td>5.408363</td>\n",
       "      <td>14.495581</td>\n",
       "      <td>13.733812</td>\n",
       "      <td>9.783708</td>\n",
       "      <td>14.324024</td>\n",
       "      <td>20.144810</td>\n",
       "      <td>30.082395</td>\n",
       "      <td>...</td>\n",
       "      <td>9.739919</td>\n",
       "      <td>13.557473</td>\n",
       "      <td>17.266452</td>\n",
       "      <td>12.023588</td>\n",
       "      <td>22.858538</td>\n",
       "      <td>21.354886</td>\n",
       "      <td>18.891045</td>\n",
       "      <td>25.606971</td>\n",
       "      <td>16.162705</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id00060</th>\n",
       "      <td>0.870490</td>\n",
       "      <td>0.837705</td>\n",
       "      <td>0.785784</td>\n",
       "      <td>1.024467</td>\n",
       "      <td>1.516620</td>\n",
       "      <td>1.509555</td>\n",
       "      <td>1.416796</td>\n",
       "      <td>1.145719</td>\n",
       "      <td>0.865605</td>\n",
       "      <td>0.919184</td>\n",
       "      <td>...</td>\n",
       "      <td>16.878267</td>\n",
       "      <td>6.008833</td>\n",
       "      <td>10.918266</td>\n",
       "      <td>24.128692</td>\n",
       "      <td>5.666462</td>\n",
       "      <td>10.839936</td>\n",
       "      <td>8.961100</td>\n",
       "      <td>10.051687</td>\n",
       "      <td>15.596128</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id09203</th>\n",
       "      <td>2.832509</td>\n",
       "      <td>2.237713</td>\n",
       "      <td>2.179287</td>\n",
       "      <td>2.203686</td>\n",
       "      <td>2.280624</td>\n",
       "      <td>3.425614</td>\n",
       "      <td>1.519659</td>\n",
       "      <td>2.486813</td>\n",
       "      <td>3.151236</td>\n",
       "      <td>2.102251</td>\n",
       "      <td>...</td>\n",
       "      <td>6.666733</td>\n",
       "      <td>8.614725</td>\n",
       "      <td>2.605896</td>\n",
       "      <td>7.061690</td>\n",
       "      <td>10.586731</td>\n",
       "      <td>4.713428</td>\n",
       "      <td>6.368062</td>\n",
       "      <td>7.663880</td>\n",
       "      <td>5.883139</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id09204</th>\n",
       "      <td>1.137614</td>\n",
       "      <td>0.939654</td>\n",
       "      <td>0.906842</td>\n",
       "      <td>0.943251</td>\n",
       "      <td>1.092192</td>\n",
       "      <td>0.685687</td>\n",
       "      <td>1.412969</td>\n",
       "      <td>0.788808</td>\n",
       "      <td>0.972282</td>\n",
       "      <td>1.073812</td>\n",
       "      <td>...</td>\n",
       "      <td>11.884353</td>\n",
       "      <td>16.317833</td>\n",
       "      <td>17.603609</td>\n",
       "      <td>17.014502</td>\n",
       "      <td>21.477971</td>\n",
       "      <td>13.900732</td>\n",
       "      <td>25.305712</td>\n",
       "      <td>13.302571</td>\n",
       "      <td>36.935933</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id09205</th>\n",
       "      <td>3.618618</td>\n",
       "      <td>3.903213</td>\n",
       "      <td>2.005773</td>\n",
       "      <td>2.557930</td>\n",
       "      <td>2.022178</td>\n",
       "      <td>1.432762</td>\n",
       "      <td>1.973364</td>\n",
       "      <td>2.741799</td>\n",
       "      <td>3.044356</td>\n",
       "      <td>1.443456</td>\n",
       "      <td>...</td>\n",
       "      <td>6.216467</td>\n",
       "      <td>12.943567</td>\n",
       "      <td>9.219642</td>\n",
       "      <td>9.629220</td>\n",
       "      <td>7.754290</td>\n",
       "      <td>5.270414</td>\n",
       "      <td>8.365533</td>\n",
       "      <td>10.352451</td>\n",
       "      <td>7.275319</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id09207</th>\n",
       "      <td>0.811909</td>\n",
       "      <td>0.904161</td>\n",
       "      <td>0.958640</td>\n",
       "      <td>0.766673</td>\n",
       "      <td>1.121001</td>\n",
       "      <td>1.112514</td>\n",
       "      <td>0.935540</td>\n",
       "      <td>1.083235</td>\n",
       "      <td>0.933317</td>\n",
       "      <td>1.113521</td>\n",
       "      <td>...</td>\n",
       "      <td>8.418675</td>\n",
       "      <td>10.211063</td>\n",
       "      <td>10.070132</td>\n",
       "      <td>13.383891</td>\n",
       "      <td>3.689219</td>\n",
       "      <td>15.495913</td>\n",
       "      <td>10.125715</td>\n",
       "      <td>11.233365</td>\n",
       "      <td>12.249143</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id09210</th>\n",
       "      <td>0.738464</td>\n",
       "      <td>0.863284</td>\n",
       "      <td>1.222870</td>\n",
       "      <td>0.942637</td>\n",
       "      <td>0.794298</td>\n",
       "      <td>0.319319</td>\n",
       "      <td>1.373210</td>\n",
       "      <td>0.628543</td>\n",
       "      <td>1.546197</td>\n",
       "      <td>2.024616</td>\n",
       "      <td>...</td>\n",
       "      <td>34.422685</td>\n",
       "      <td>29.017759</td>\n",
       "      <td>24.338659</td>\n",
       "      <td>25.229305</td>\n",
       "      <td>28.776006</td>\n",
       "      <td>32.933166</td>\n",
       "      <td>38.321410</td>\n",
       "      <td>49.467456</td>\n",
       "      <td>48.534160</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id09211</th>\n",
       "      <td>4.874788</td>\n",
       "      <td>7.664593</td>\n",
       "      <td>8.008751</td>\n",
       "      <td>14.421355</td>\n",
       "      <td>10.552176</td>\n",
       "      <td>14.376884</td>\n",
       "      <td>19.540580</td>\n",
       "      <td>13.472426</td>\n",
       "      <td>6.134119</td>\n",
       "      <td>21.277002</td>\n",
       "      <td>...</td>\n",
       "      <td>124.204779</td>\n",
       "      <td>100.676707</td>\n",
       "      <td>109.772071</td>\n",
       "      <td>78.579673</td>\n",
       "      <td>51.913736</td>\n",
       "      <td>49.612829</td>\n",
       "      <td>42.937673</td>\n",
       "      <td>45.411177</td>\n",
       "      <td>90.820288</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id09212</th>\n",
       "      <td>27.565930</td>\n",
       "      <td>32.061041</td>\n",
       "      <td>26.183390</td>\n",
       "      <td>44.104563</td>\n",
       "      <td>27.745111</td>\n",
       "      <td>34.187027</td>\n",
       "      <td>39.185942</td>\n",
       "      <td>33.359874</td>\n",
       "      <td>26.864484</td>\n",
       "      <td>39.253854</td>\n",
       "      <td>...</td>\n",
       "      <td>6.831645</td>\n",
       "      <td>12.540261</td>\n",
       "      <td>8.024421</td>\n",
       "      <td>8.301893</td>\n",
       "      <td>15.332033</td>\n",
       "      <td>7.067471</td>\n",
       "      <td>7.302669</td>\n",
       "      <td>10.972449</td>\n",
       "      <td>8.564203</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id09213</th>\n",
       "      <td>4.480350</td>\n",
       "      <td>2.419517</td>\n",
       "      <td>2.800911</td>\n",
       "      <td>1.568721</td>\n",
       "      <td>1.738467</td>\n",
       "      <td>3.565729</td>\n",
       "      <td>2.588102</td>\n",
       "      <td>2.736686</td>\n",
       "      <td>1.635129</td>\n",
       "      <td>3.015792</td>\n",
       "      <td>...</td>\n",
       "      <td>34.560044</td>\n",
       "      <td>31.579656</td>\n",
       "      <td>22.522476</td>\n",
       "      <td>38.632349</td>\n",
       "      <td>28.472866</td>\n",
       "      <td>9.046342</td>\n",
       "      <td>33.117048</td>\n",
       "      <td>31.834561</td>\n",
       "      <td>39.096932</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id09214</th>\n",
       "      <td>7.095983</td>\n",
       "      <td>10.780186</td>\n",
       "      <td>8.716306</td>\n",
       "      <td>10.978448</td>\n",
       "      <td>8.864301</td>\n",
       "      <td>4.301024</td>\n",
       "      <td>7.571861</td>\n",
       "      <td>8.806215</td>\n",
       "      <td>7.579309</td>\n",
       "      <td>9.005128</td>\n",
       "      <td>...</td>\n",
       "      <td>11.984041</td>\n",
       "      <td>21.011953</td>\n",
       "      <td>8.555213</td>\n",
       "      <td>21.559275</td>\n",
       "      <td>30.066025</td>\n",
       "      <td>16.531457</td>\n",
       "      <td>23.348284</td>\n",
       "      <td>17.976584</td>\n",
       "      <td>13.224837</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id09215</th>\n",
       "      <td>4.546918</td>\n",
       "      <td>3.783237</td>\n",
       "      <td>3.007006</td>\n",
       "      <td>2.283148</td>\n",
       "      <td>5.190321</td>\n",
       "      <td>5.518032</td>\n",
       "      <td>3.528290</td>\n",
       "      <td>1.197755</td>\n",
       "      <td>4.364169</td>\n",
       "      <td>3.750236</td>\n",
       "      <td>...</td>\n",
       "      <td>30.361829</td>\n",
       "      <td>23.003806</td>\n",
       "      <td>12.893036</td>\n",
       "      <td>18.806138</td>\n",
       "      <td>19.919925</td>\n",
       "      <td>28.183909</td>\n",
       "      <td>34.023825</td>\n",
       "      <td>35.584575</td>\n",
       "      <td>35.359570</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id09216</th>\n",
       "      <td>14.565888</td>\n",
       "      <td>12.478568</td>\n",
       "      <td>3.864536</td>\n",
       "      <td>5.644767</td>\n",
       "      <td>3.825817</td>\n",
       "      <td>20.945853</td>\n",
       "      <td>4.231831</td>\n",
       "      <td>8.214061</td>\n",
       "      <td>3.921133</td>\n",
       "      <td>7.120531</td>\n",
       "      <td>...</td>\n",
       "      <td>65.186979</td>\n",
       "      <td>39.795431</td>\n",
       "      <td>40.639845</td>\n",
       "      <td>21.139338</td>\n",
       "      <td>50.090595</td>\n",
       "      <td>52.256173</td>\n",
       "      <td>44.333512</td>\n",
       "      <td>20.904155</td>\n",
       "      <td>38.298939</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id09218</th>\n",
       "      <td>10.685590</td>\n",
       "      <td>10.182629</td>\n",
       "      <td>6.386231</td>\n",
       "      <td>7.798449</td>\n",
       "      <td>10.942327</td>\n",
       "      <td>10.518225</td>\n",
       "      <td>8.775012</td>\n",
       "      <td>12.217125</td>\n",
       "      <td>11.330881</td>\n",
       "      <td>9.198312</td>\n",
       "      <td>...</td>\n",
       "      <td>4.008785</td>\n",
       "      <td>2.676367</td>\n",
       "      <td>2.991700</td>\n",
       "      <td>3.288622</td>\n",
       "      <td>3.141552</td>\n",
       "      <td>2.960952</td>\n",
       "      <td>3.469950</td>\n",
       "      <td>2.824201</td>\n",
       "      <td>2.898943</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id09220</th>\n",
       "      <td>1.110444</td>\n",
       "      <td>1.084174</td>\n",
       "      <td>1.646376</td>\n",
       "      <td>0.737141</td>\n",
       "      <td>1.383049</td>\n",
       "      <td>1.153580</td>\n",
       "      <td>1.666779</td>\n",
       "      <td>0.928837</td>\n",
       "      <td>0.753549</td>\n",
       "      <td>0.811250</td>\n",
       "      <td>...</td>\n",
       "      <td>11.756175</td>\n",
       "      <td>16.064714</td>\n",
       "      <td>20.485758</td>\n",
       "      <td>15.723109</td>\n",
       "      <td>20.815179</td>\n",
       "      <td>17.072322</td>\n",
       "      <td>12.727123</td>\n",
       "      <td>11.075252</td>\n",
       "      <td>13.690630</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id09222</th>\n",
       "      <td>5.754977</td>\n",
       "      <td>10.213594</td>\n",
       "      <td>12.082435</td>\n",
       "      <td>15.471743</td>\n",
       "      <td>16.099064</td>\n",
       "      <td>11.346488</td>\n",
       "      <td>18.680828</td>\n",
       "      <td>28.164855</td>\n",
       "      <td>23.889184</td>\n",
       "      <td>36.433960</td>\n",
       "      <td>...</td>\n",
       "      <td>21.878746</td>\n",
       "      <td>18.751589</td>\n",
       "      <td>25.763070</td>\n",
       "      <td>25.572644</td>\n",
       "      <td>19.308963</td>\n",
       "      <td>20.808632</td>\n",
       "      <td>21.679499</td>\n",
       "      <td>19.383145</td>\n",
       "      <td>29.803869</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id09224</th>\n",
       "      <td>0.170572</td>\n",
       "      <td>0.569311</td>\n",
       "      <td>1.215884</td>\n",
       "      <td>0.329359</td>\n",
       "      <td>0.492826</td>\n",
       "      <td>0.611527</td>\n",
       "      <td>0.687219</td>\n",
       "      <td>0.764657</td>\n",
       "      <td>1.267150</td>\n",
       "      <td>0.700350</td>\n",
       "      <td>...</td>\n",
       "      <td>2.884363</td>\n",
       "      <td>1.298001</td>\n",
       "      <td>2.164361</td>\n",
       "      <td>2.584368</td>\n",
       "      <td>3.809047</td>\n",
       "      <td>1.977162</td>\n",
       "      <td>3.755238</td>\n",
       "      <td>4.002905</td>\n",
       "      <td>4.239678</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id09225</th>\n",
       "      <td>0.163235</td>\n",
       "      <td>0.194355</td>\n",
       "      <td>0.111552</td>\n",
       "      <td>0.184620</td>\n",
       "      <td>0.182679</td>\n",
       "      <td>0.238886</td>\n",
       "      <td>0.169165</td>\n",
       "      <td>0.250339</td>\n",
       "      <td>0.173989</td>\n",
       "      <td>0.188257</td>\n",
       "      <td>...</td>\n",
       "      <td>1.848476</td>\n",
       "      <td>2.963235</td>\n",
       "      <td>3.636033</td>\n",
       "      <td>2.730165</td>\n",
       "      <td>2.929879</td>\n",
       "      <td>3.985328</td>\n",
       "      <td>3.585039</td>\n",
       "      <td>3.849685</td>\n",
       "      <td>3.259752</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id09227</th>\n",
       "      <td>9.105467</td>\n",
       "      <td>6.816515</td>\n",
       "      <td>8.738522</td>\n",
       "      <td>8.702930</td>\n",
       "      <td>5.218566</td>\n",
       "      <td>8.970633</td>\n",
       "      <td>11.297906</td>\n",
       "      <td>7.510847</td>\n",
       "      <td>9.048519</td>\n",
       "      <td>8.304502</td>\n",
       "      <td>...</td>\n",
       "      <td>29.800998</td>\n",
       "      <td>28.219907</td>\n",
       "      <td>18.391265</td>\n",
       "      <td>20.253477</td>\n",
       "      <td>14.887664</td>\n",
       "      <td>20.266730</td>\n",
       "      <td>15.966737</td>\n",
       "      <td>24.321330</td>\n",
       "      <td>7.125147</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id09230</th>\n",
       "      <td>2.458459</td>\n",
       "      <td>3.316224</td>\n",
       "      <td>1.561777</td>\n",
       "      <td>3.277923</td>\n",
       "      <td>2.530390</td>\n",
       "      <td>2.975842</td>\n",
       "      <td>3.632895</td>\n",
       "      <td>3.163505</td>\n",
       "      <td>3.833280</td>\n",
       "      <td>6.650067</td>\n",
       "      <td>...</td>\n",
       "      <td>14.684198</td>\n",
       "      <td>20.482149</td>\n",
       "      <td>9.028393</td>\n",
       "      <td>10.502804</td>\n",
       "      <td>20.442034</td>\n",
       "      <td>14.935364</td>\n",
       "      <td>17.613298</td>\n",
       "      <td>17.871577</td>\n",
       "      <td>16.711567</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id09232</th>\n",
       "      <td>0.448652</td>\n",
       "      <td>0.323116</td>\n",
       "      <td>0.877968</td>\n",
       "      <td>0.792433</td>\n",
       "      <td>0.471289</td>\n",
       "      <td>0.740132</td>\n",
       "      <td>0.776745</td>\n",
       "      <td>0.822606</td>\n",
       "      <td>0.871877</td>\n",
       "      <td>0.654031</td>\n",
       "      <td>...</td>\n",
       "      <td>22.023640</td>\n",
       "      <td>26.111909</td>\n",
       "      <td>24.346478</td>\n",
       "      <td>16.854439</td>\n",
       "      <td>21.473921</td>\n",
       "      <td>19.001181</td>\n",
       "      <td>25.201281</td>\n",
       "      <td>22.084093</td>\n",
       "      <td>20.928128</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id09234</th>\n",
       "      <td>0.412088</td>\n",
       "      <td>1.024893</td>\n",
       "      <td>3.122072</td>\n",
       "      <td>1.099778</td>\n",
       "      <td>2.073965</td>\n",
       "      <td>0.892866</td>\n",
       "      <td>1.707288</td>\n",
       "      <td>0.697771</td>\n",
       "      <td>2.117171</td>\n",
       "      <td>0.812697</td>\n",
       "      <td>...</td>\n",
       "      <td>6.419497</td>\n",
       "      <td>5.243067</td>\n",
       "      <td>6.272496</td>\n",
       "      <td>8.554282</td>\n",
       "      <td>5.806077</td>\n",
       "      <td>8.970606</td>\n",
       "      <td>6.263301</td>\n",
       "      <td>7.897838</td>\n",
       "      <td>9.624410</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id09235</th>\n",
       "      <td>3.042342</td>\n",
       "      <td>4.067194</td>\n",
       "      <td>1.841117</td>\n",
       "      <td>2.494903</td>\n",
       "      <td>3.147973</td>\n",
       "      <td>4.270330</td>\n",
       "      <td>3.038040</td>\n",
       "      <td>3.630735</td>\n",
       "      <td>3.264174</td>\n",
       "      <td>2.936744</td>\n",
       "      <td>...</td>\n",
       "      <td>7.299262</td>\n",
       "      <td>12.191400</td>\n",
       "      <td>9.138245</td>\n",
       "      <td>19.912400</td>\n",
       "      <td>18.953538</td>\n",
       "      <td>19.900709</td>\n",
       "      <td>15.888872</td>\n",
       "      <td>7.825175</td>\n",
       "      <td>14.109119</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id09236</th>\n",
       "      <td>6.008754</td>\n",
       "      <td>6.248678</td>\n",
       "      <td>2.303596</td>\n",
       "      <td>2.511806</td>\n",
       "      <td>5.200047</td>\n",
       "      <td>3.752901</td>\n",
       "      <td>4.102437</td>\n",
       "      <td>5.830283</td>\n",
       "      <td>6.211680</td>\n",
       "      <td>5.329992</td>\n",
       "      <td>...</td>\n",
       "      <td>18.832658</td>\n",
       "      <td>17.912724</td>\n",
       "      <td>23.100738</td>\n",
       "      <td>19.620891</td>\n",
       "      <td>26.591068</td>\n",
       "      <td>31.507824</td>\n",
       "      <td>23.019418</td>\n",
       "      <td>24.264499</td>\n",
       "      <td>30.028316</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id09237</th>\n",
       "      <td>15.429433</td>\n",
       "      <td>10.092394</td>\n",
       "      <td>16.147367</td>\n",
       "      <td>24.370092</td>\n",
       "      <td>40.409459</td>\n",
       "      <td>88.139495</td>\n",
       "      <td>79.712377</td>\n",
       "      <td>52.543509</td>\n",
       "      <td>45.299273</td>\n",
       "      <td>25.776504</td>\n",
       "      <td>...</td>\n",
       "      <td>22.696995</td>\n",
       "      <td>25.089522</td>\n",
       "      <td>29.639162</td>\n",
       "      <td>45.935745</td>\n",
       "      <td>45.418208</td>\n",
       "      <td>40.110261</td>\n",
       "      <td>30.178227</td>\n",
       "      <td>32.311612</td>\n",
       "      <td>41.688222</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id09242</th>\n",
       "      <td>0.479008</td>\n",
       "      <td>0.469717</td>\n",
       "      <td>0.400617</td>\n",
       "      <td>0.433764</td>\n",
       "      <td>0.724111</td>\n",
       "      <td>0.528022</td>\n",
       "      <td>1.015034</td>\n",
       "      <td>0.405481</td>\n",
       "      <td>0.259741</td>\n",
       "      <td>0.349557</td>\n",
       "      <td>...</td>\n",
       "      <td>10.614871</td>\n",
       "      <td>9.459178</td>\n",
       "      <td>10.581231</td>\n",
       "      <td>8.093368</td>\n",
       "      <td>7.884852</td>\n",
       "      <td>5.484525</td>\n",
       "      <td>3.428962</td>\n",
       "      <td>6.369811</td>\n",
       "      <td>11.240044</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id09243</th>\n",
       "      <td>1.981209</td>\n",
       "      <td>1.813247</td>\n",
       "      <td>2.143046</td>\n",
       "      <td>2.462726</td>\n",
       "      <td>2.658822</td>\n",
       "      <td>2.659318</td>\n",
       "      <td>2.316983</td>\n",
       "      <td>1.977790</td>\n",
       "      <td>1.834886</td>\n",
       "      <td>0.849233</td>\n",
       "      <td>...</td>\n",
       "      <td>3.990286</td>\n",
       "      <td>3.054173</td>\n",
       "      <td>5.262082</td>\n",
       "      <td>6.097992</td>\n",
       "      <td>7.160038</td>\n",
       "      <td>7.359117</td>\n",
       "      <td>7.173589</td>\n",
       "      <td>5.972636</td>\n",
       "      <td>6.233966</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id09245</th>\n",
       "      <td>6.358695</td>\n",
       "      <td>6.121464</td>\n",
       "      <td>7.718537</td>\n",
       "      <td>6.223124</td>\n",
       "      <td>5.647512</td>\n",
       "      <td>4.782130</td>\n",
       "      <td>4.376102</td>\n",
       "      <td>5.315562</td>\n",
       "      <td>3.954588</td>\n",
       "      <td>6.315027</td>\n",
       "      <td>...</td>\n",
       "      <td>102.466982</td>\n",
       "      <td>98.269666</td>\n",
       "      <td>122.615883</td>\n",
       "      <td>124.841665</td>\n",
       "      <td>131.531489</td>\n",
       "      <td>110.034130</td>\n",
       "      <td>140.373393</td>\n",
       "      <td>111.748909</td>\n",
       "      <td>91.277771</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id09263</th>\n",
       "      <td>15.340253</td>\n",
       "      <td>9.455475</td>\n",
       "      <td>12.515357</td>\n",
       "      <td>17.838015</td>\n",
       "      <td>10.897729</td>\n",
       "      <td>5.787740</td>\n",
       "      <td>4.354970</td>\n",
       "      <td>10.582315</td>\n",
       "      <td>6.487403</td>\n",
       "      <td>6.979881</td>\n",
       "      <td>...</td>\n",
       "      <td>27.480486</td>\n",
       "      <td>22.908311</td>\n",
       "      <td>15.832876</td>\n",
       "      <td>24.174689</td>\n",
       "      <td>25.632456</td>\n",
       "      <td>18.613701</td>\n",
       "      <td>11.817848</td>\n",
       "      <td>21.894774</td>\n",
       "      <td>19.228095</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id09268</th>\n",
       "      <td>1.848201</td>\n",
       "      <td>0.694505</td>\n",
       "      <td>0.795584</td>\n",
       "      <td>2.317926</td>\n",
       "      <td>1.924938</td>\n",
       "      <td>1.995157</td>\n",
       "      <td>1.577052</td>\n",
       "      <td>1.245525</td>\n",
       "      <td>1.107462</td>\n",
       "      <td>0.906246</td>\n",
       "      <td>...</td>\n",
       "      <td>14.492760</td>\n",
       "      <td>12.681758</td>\n",
       "      <td>20.156112</td>\n",
       "      <td>11.622521</td>\n",
       "      <td>19.214027</td>\n",
       "      <td>25.224146</td>\n",
       "      <td>18.133056</td>\n",
       "      <td>28.581963</td>\n",
       "      <td>10.892175</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id09269</th>\n",
       "      <td>0.230421</td>\n",
       "      <td>0.363599</td>\n",
       "      <td>0.265292</td>\n",
       "      <td>0.327284</td>\n",
       "      <td>0.213717</td>\n",
       "      <td>0.450051</td>\n",
       "      <td>0.217411</td>\n",
       "      <td>0.268453</td>\n",
       "      <td>0.238348</td>\n",
       "      <td>0.232172</td>\n",
       "      <td>...</td>\n",
       "      <td>8.083142</td>\n",
       "      <td>9.320389</td>\n",
       "      <td>13.236724</td>\n",
       "      <td>11.522078</td>\n",
       "      <td>9.387657</td>\n",
       "      <td>7.679590</td>\n",
       "      <td>13.536814</td>\n",
       "      <td>10.799883</td>\n",
       "      <td>18.118513</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id09272</th>\n",
       "      <td>48.346068</td>\n",
       "      <td>60.559842</td>\n",
       "      <td>50.895229</td>\n",
       "      <td>53.119645</td>\n",
       "      <td>47.716528</td>\n",
       "      <td>26.905532</td>\n",
       "      <td>25.999056</td>\n",
       "      <td>49.704548</td>\n",
       "      <td>99.754506</td>\n",
       "      <td>52.412458</td>\n",
       "      <td>...</td>\n",
       "      <td>38.549170</td>\n",
       "      <td>81.498125</td>\n",
       "      <td>63.005649</td>\n",
       "      <td>51.221141</td>\n",
       "      <td>48.416304</td>\n",
       "      <td>37.475533</td>\n",
       "      <td>60.163159</td>\n",
       "      <td>64.886583</td>\n",
       "      <td>49.516520</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4959 rows × 191 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0          1          2          3          4          5  \\\n",
       "ID                                                                          \n",
       "id00012   2.666514   1.736939   1.158345   1.790269   2.128618   1.917723   \n",
       "id00018   3.866567   3.308477   2.099306   1.620708   2.995494   1.519316   \n",
       "id00019   0.980058   1.837420   1.152202   1.165895   1.816326   1.333596   \n",
       "id00020   2.470025   2.683406   1.566433   1.576143   2.716434   5.700669   \n",
       "id00022   8.510809   4.013943  10.465756  14.430515  14.115017  15.512525   \n",
       "id00024   0.562785   0.462425   0.741593   0.578841   1.046791   1.025440   \n",
       "id00025   0.153742   0.175582   0.265045   0.241335   0.159157   0.322375   \n",
       "id00026   1.130349   1.061265   1.191811   1.646337   2.395768   0.817556   \n",
       "id00027   2.323866   1.204467   1.469019   1.509376   2.343780   2.108433   \n",
       "id00028   3.035594   2.147924   1.817727   2.678931   2.041058   2.174266   \n",
       "id00029   2.132380   1.190861   0.813621   1.982442   2.653803   2.724420   \n",
       "id00032   4.062975   3.532017   4.333744   4.780152   2.476107   4.024173   \n",
       "id00033   2.387803   2.062441   1.853585   2.418103   2.013974   1.816602   \n",
       "id00035   0.726346   0.917897   0.723405   0.707427   0.812177   1.142542   \n",
       "id00036   7.323147  12.031888  13.678829   4.984016   6.831900   3.963119   \n",
       "id00039   9.507171   4.851099   6.765448   7.961253   5.164460   6.878731   \n",
       "id00040   1.268790   0.941258   1.709855   1.393628   1.715932   1.431332   \n",
       "id00042   7.013058  29.560124  24.166933  23.341047  14.778809  31.705640   \n",
       "id00043   1.083236   0.709477   0.230486   0.431884   1.058905   0.697872   \n",
       "id00044   2.328791   5.229773   4.376595   4.972605   3.817128   6.408254   \n",
       "id00047   2.630139   3.704673   2.406458   3.505847   2.259006   3.479831   \n",
       "id00049   5.060342   6.103115  10.074891   5.898734   5.529209  12.751007   \n",
       "id00051  28.949994  38.374034  24.113973  28.754525  27.823202  30.088761   \n",
       "id00052   0.574329   0.472937   0.770717   0.547800   0.586500   0.392446   \n",
       "id00053   5.998414   3.995160   4.467448   5.241607   4.290500   6.095347   \n",
       "id00055   0.413586   0.987610   0.683441   0.471844   0.867311   1.675066   \n",
       "id00056   5.348130   6.387375   8.161529   7.274211   4.859745   5.255259   \n",
       "id00058   0.701271   1.360822   1.250774   0.995929   1.221501   1.772693   \n",
       "id00059  19.545645   8.438138   6.780867   5.408363  14.495581  13.733812   \n",
       "id00060   0.870490   0.837705   0.785784   1.024467   1.516620   1.509555   \n",
       "...            ...        ...        ...        ...        ...        ...   \n",
       "id09203   2.832509   2.237713   2.179287   2.203686   2.280624   3.425614   \n",
       "id09204   1.137614   0.939654   0.906842   0.943251   1.092192   0.685687   \n",
       "id09205   3.618618   3.903213   2.005773   2.557930   2.022178   1.432762   \n",
       "id09207   0.811909   0.904161   0.958640   0.766673   1.121001   1.112514   \n",
       "id09210   0.738464   0.863284   1.222870   0.942637   0.794298   0.319319   \n",
       "id09211   4.874788   7.664593   8.008751  14.421355  10.552176  14.376884   \n",
       "id09212  27.565930  32.061041  26.183390  44.104563  27.745111  34.187027   \n",
       "id09213   4.480350   2.419517   2.800911   1.568721   1.738467   3.565729   \n",
       "id09214   7.095983  10.780186   8.716306  10.978448   8.864301   4.301024   \n",
       "id09215   4.546918   3.783237   3.007006   2.283148   5.190321   5.518032   \n",
       "id09216  14.565888  12.478568   3.864536   5.644767   3.825817  20.945853   \n",
       "id09218  10.685590  10.182629   6.386231   7.798449  10.942327  10.518225   \n",
       "id09220   1.110444   1.084174   1.646376   0.737141   1.383049   1.153580   \n",
       "id09222   5.754977  10.213594  12.082435  15.471743  16.099064  11.346488   \n",
       "id09224   0.170572   0.569311   1.215884   0.329359   0.492826   0.611527   \n",
       "id09225   0.163235   0.194355   0.111552   0.184620   0.182679   0.238886   \n",
       "id09227   9.105467   6.816515   8.738522   8.702930   5.218566   8.970633   \n",
       "id09230   2.458459   3.316224   1.561777   3.277923   2.530390   2.975842   \n",
       "id09232   0.448652   0.323116   0.877968   0.792433   0.471289   0.740132   \n",
       "id09234   0.412088   1.024893   3.122072   1.099778   2.073965   0.892866   \n",
       "id09235   3.042342   4.067194   1.841117   2.494903   3.147973   4.270330   \n",
       "id09236   6.008754   6.248678   2.303596   2.511806   5.200047   3.752901   \n",
       "id09237  15.429433  10.092394  16.147367  24.370092  40.409459  88.139495   \n",
       "id09242   0.479008   0.469717   0.400617   0.433764   0.724111   0.528022   \n",
       "id09243   1.981209   1.813247   2.143046   2.462726   2.658822   2.659318   \n",
       "id09245   6.358695   6.121464   7.718537   6.223124   5.647512   4.782130   \n",
       "id09263  15.340253   9.455475  12.515357  17.838015  10.897729   5.787740   \n",
       "id09268   1.848201   0.694505   0.795584   2.317926   1.924938   1.995157   \n",
       "id09269   0.230421   0.363599   0.265292   0.327284   0.213717   0.450051   \n",
       "id09272  48.346068  60.559842  50.895229  53.119645  47.716528  26.905532   \n",
       "\n",
       "                 6          7          8          9 ...          181  \\\n",
       "ID                                                  ...                \n",
       "id00012   1.524069   4.657731   1.383169   3.673608 ...     2.444855   \n",
       "id00018   3.004626   1.265518   2.483844   3.510914 ...    16.853714   \n",
       "id00019   0.929478   1.197637   1.589045   2.073400 ...    22.754171   \n",
       "id00020   3.974343   5.858382   3.004119   6.376210 ...     8.265149   \n",
       "id00022  18.147178  10.152281   7.566912  10.432986 ...     6.530424   \n",
       "id00024   1.032807   0.877103   0.832526   1.622779 ...    37.557951   \n",
       "id00025   0.322586   0.456646   0.245129   0.319397 ...     8.172353   \n",
       "id00026   1.597435   1.676377   1.178263   1.578277 ...    28.167205   \n",
       "id00027   1.045771   2.714258   1.079049   1.604778 ...    21.137971   \n",
       "id00028   3.932939   2.096481   1.500588   1.898173 ...     7.816985   \n",
       "id00029   4.109868   1.467896   5.525037   2.591005 ...    30.130817   \n",
       "id00032   3.684624   4.362876   1.364309   2.257892 ...    14.400048   \n",
       "id00033   3.007126   3.032722   2.102787   3.284746 ...    20.290933   \n",
       "id00035   1.031773   1.240735   1.070356   0.923115 ...    11.733148   \n",
       "id00036   7.436767   6.448851   9.539648  12.746929 ...     9.030141   \n",
       "id00039   3.940919   6.018472   4.569367   4.712691 ...    27.180280   \n",
       "id00040   1.583902   1.862646   1.582926   1.566749 ...    16.507210   \n",
       "id00042   6.522730  17.037722  18.025191   7.575657 ...   151.733320   \n",
       "id00043   0.933384   0.927028   1.029810   0.758568 ...    19.443915   \n",
       "id00044   4.726422   3.700584   2.582421   1.966189 ...     8.558032   \n",
       "id00047   4.203078   4.996240   3.384179   3.526166 ...    23.115702   \n",
       "id00049   6.974557   6.293443   8.945688   6.715341 ...     8.755644   \n",
       "id00051  59.844800  33.248550  54.488929  35.329123 ...   142.136361   \n",
       "id00052   0.805393   0.589383   0.261549   0.675292 ...     3.074363   \n",
       "id00053   1.928679   7.316389   2.999429   8.383681 ...    10.526931   \n",
       "id00055   1.534770   1.219493   2.195528   1.815940 ...     3.423476   \n",
       "id00056   5.442443   4.761402   2.743283   4.591072 ...    11.123622   \n",
       "id00058   0.953341   0.957259   1.798072   1.544146 ...    17.031646   \n",
       "id00059   9.783708  14.324024  20.144810  30.082395 ...     9.739919   \n",
       "id00060   1.416796   1.145719   0.865605   0.919184 ...    16.878267   \n",
       "...            ...        ...        ...        ... ...          ...   \n",
       "id09203   1.519659   2.486813   3.151236   2.102251 ...     6.666733   \n",
       "id09204   1.412969   0.788808   0.972282   1.073812 ...    11.884353   \n",
       "id09205   1.973364   2.741799   3.044356   1.443456 ...     6.216467   \n",
       "id09207   0.935540   1.083235   0.933317   1.113521 ...     8.418675   \n",
       "id09210   1.373210   0.628543   1.546197   2.024616 ...    34.422685   \n",
       "id09211  19.540580  13.472426   6.134119  21.277002 ...   124.204779   \n",
       "id09212  39.185942  33.359874  26.864484  39.253854 ...     6.831645   \n",
       "id09213   2.588102   2.736686   1.635129   3.015792 ...    34.560044   \n",
       "id09214   7.571861   8.806215   7.579309   9.005128 ...    11.984041   \n",
       "id09215   3.528290   1.197755   4.364169   3.750236 ...    30.361829   \n",
       "id09216   4.231831   8.214061   3.921133   7.120531 ...    65.186979   \n",
       "id09218   8.775012  12.217125  11.330881   9.198312 ...     4.008785   \n",
       "id09220   1.666779   0.928837   0.753549   0.811250 ...    11.756175   \n",
       "id09222  18.680828  28.164855  23.889184  36.433960 ...    21.878746   \n",
       "id09224   0.687219   0.764657   1.267150   0.700350 ...     2.884363   \n",
       "id09225   0.169165   0.250339   0.173989   0.188257 ...     1.848476   \n",
       "id09227  11.297906   7.510847   9.048519   8.304502 ...    29.800998   \n",
       "id09230   3.632895   3.163505   3.833280   6.650067 ...    14.684198   \n",
       "id09232   0.776745   0.822606   0.871877   0.654031 ...    22.023640   \n",
       "id09234   1.707288   0.697771   2.117171   0.812697 ...     6.419497   \n",
       "id09235   3.038040   3.630735   3.264174   2.936744 ...     7.299262   \n",
       "id09236   4.102437   5.830283   6.211680   5.329992 ...    18.832658   \n",
       "id09237  79.712377  52.543509  45.299273  25.776504 ...    22.696995   \n",
       "id09242   1.015034   0.405481   0.259741   0.349557 ...    10.614871   \n",
       "id09243   2.316983   1.977790   1.834886   0.849233 ...     3.990286   \n",
       "id09245   4.376102   5.315562   3.954588   6.315027 ...   102.466982   \n",
       "id09263   4.354970  10.582315   6.487403   6.979881 ...    27.480486   \n",
       "id09268   1.577052   1.245525   1.107462   0.906246 ...    14.492760   \n",
       "id09269   0.217411   0.268453   0.238348   0.232172 ...     8.083142   \n",
       "id09272  25.999056  49.704548  99.754506  52.412458 ...    38.549170   \n",
       "\n",
       "                182         183         184         185         186  \\\n",
       "ID                                                                    \n",
       "id00012    2.127628    2.109255    3.181896    2.111263    2.259769   \n",
       "id00018   22.786992   10.819950   12.771045   25.415175   14.065540   \n",
       "id00019   19.628845   23.227182   10.786076   24.588652   15.593162   \n",
       "id00020    7.629799    7.695075    3.251242    4.987161    6.515693   \n",
       "id00022    5.774186    7.149016    5.980288    6.341032    5.824727   \n",
       "id00024   11.946116   22.955237   36.019117   21.584943    6.990265   \n",
       "id00025    5.372250    5.221166    6.090531    4.805570    4.058229   \n",
       "id00026   28.936205   25.966203   25.165950   19.824578   28.227274   \n",
       "id00027   14.969207   13.792308   15.594114   10.566836   25.369816   \n",
       "id00028    8.352660   10.500431   10.447789    5.659825    9.092096   \n",
       "id00029   15.017449   19.411332   21.692557   15.602820   12.881429   \n",
       "id00032    8.826859    4.613547    6.786347    6.959559    3.976563   \n",
       "id00033   13.709683   16.740742   14.657354   15.698034   20.802737   \n",
       "id00035   22.343121   17.423413   16.616798   11.894639   19.319168   \n",
       "id00036    5.529461    8.289636   23.512148   29.349329   10.607384   \n",
       "id00039   22.255941   21.116806   18.541870   10.345109   15.615980   \n",
       "id00040   17.890345   12.408214   14.521081   20.119526   10.133350   \n",
       "id00042   74.755521  101.662205  124.714312  149.425271  142.791953   \n",
       "id00043   20.111314   23.573624   25.235381   31.427178   24.909478   \n",
       "id00044    8.117445    7.023194   12.667714   15.671313   18.162131   \n",
       "id00047   23.884573   24.580932   18.925946   22.296105   13.982835   \n",
       "id00049    3.048386    4.314952    5.001781    8.758627    8.887190   \n",
       "id00051  142.157074  120.014727   94.835124  191.868755  206.279904   \n",
       "id00052    3.281674    3.834960    5.002620    7.024471    4.164413   \n",
       "id00053    6.975480    4.859496    7.349589    3.780885   12.557552   \n",
       "id00055    2.593513    3.140839    3.679644    3.378531    0.953940   \n",
       "id00056    7.105595    7.765454    9.896080    3.701304    9.744414   \n",
       "id00058   23.497007   13.849762   27.339371   29.412244   32.002158   \n",
       "id00059   13.557473   17.266452   12.023588   22.858538   21.354886   \n",
       "id00060    6.008833   10.918266   24.128692    5.666462   10.839936   \n",
       "...             ...         ...         ...         ...         ...   \n",
       "id09203    8.614725    2.605896    7.061690   10.586731    4.713428   \n",
       "id09204   16.317833   17.603609   17.014502   21.477971   13.900732   \n",
       "id09205   12.943567    9.219642    9.629220    7.754290    5.270414   \n",
       "id09207   10.211063   10.070132   13.383891    3.689219   15.495913   \n",
       "id09210   29.017759   24.338659   25.229305   28.776006   32.933166   \n",
       "id09211  100.676707  109.772071   78.579673   51.913736   49.612829   \n",
       "id09212   12.540261    8.024421    8.301893   15.332033    7.067471   \n",
       "id09213   31.579656   22.522476   38.632349   28.472866    9.046342   \n",
       "id09214   21.011953    8.555213   21.559275   30.066025   16.531457   \n",
       "id09215   23.003806   12.893036   18.806138   19.919925   28.183909   \n",
       "id09216   39.795431   40.639845   21.139338   50.090595   52.256173   \n",
       "id09218    2.676367    2.991700    3.288622    3.141552    2.960952   \n",
       "id09220   16.064714   20.485758   15.723109   20.815179   17.072322   \n",
       "id09222   18.751589   25.763070   25.572644   19.308963   20.808632   \n",
       "id09224    1.298001    2.164361    2.584368    3.809047    1.977162   \n",
       "id09225    2.963235    3.636033    2.730165    2.929879    3.985328   \n",
       "id09227   28.219907   18.391265   20.253477   14.887664   20.266730   \n",
       "id09230   20.482149    9.028393   10.502804   20.442034   14.935364   \n",
       "id09232   26.111909   24.346478   16.854439   21.473921   19.001181   \n",
       "id09234    5.243067    6.272496    8.554282    5.806077    8.970606   \n",
       "id09235   12.191400    9.138245   19.912400   18.953538   19.900709   \n",
       "id09236   17.912724   23.100738   19.620891   26.591068   31.507824   \n",
       "id09237   25.089522   29.639162   45.935745   45.418208   40.110261   \n",
       "id09242    9.459178   10.581231    8.093368    7.884852    5.484525   \n",
       "id09243    3.054173    5.262082    6.097992    7.160038    7.359117   \n",
       "id09245   98.269666  122.615883  124.841665  131.531489  110.034130   \n",
       "id09263   22.908311   15.832876   24.174689   25.632456   18.613701   \n",
       "id09268   12.681758   20.156112   11.622521   19.214027   25.224146   \n",
       "id09269    9.320389   13.236724   11.522078    9.387657    7.679590   \n",
       "id09272   81.498125   63.005649   51.221141   48.416304   37.475533   \n",
       "\n",
       "                187         188         189  Sex  \n",
       "ID                                                \n",
       "id00012    1.353609    2.217303    4.026561    1  \n",
       "id00018   18.978004   19.324807   14.908907    1  \n",
       "id00019   14.239353   23.147509   12.935843    1  \n",
       "id00020    5.976787    4.146975    6.702565    1  \n",
       "id00022    8.058199    6.044662   11.776013    0  \n",
       "id00024   14.425140   19.600922   16.230263    0  \n",
       "id00025    3.893476    2.855270    1.911586    0  \n",
       "id00026   17.603077   21.637453   22.866847    1  \n",
       "id00027   28.334713   29.244976   25.269735    1  \n",
       "id00028   12.999733    4.316463    8.383385    1  \n",
       "id00029   16.821884   14.993693   21.802091    1  \n",
       "id00032    6.482851    7.695543    1.695017    1  \n",
       "id00033   12.250548   14.791108   10.808265    1  \n",
       "id00035   15.578912    7.052004    6.677454    1  \n",
       "id00036   15.829012   25.250293   18.017826    1  \n",
       "id00039   15.188607   25.551843   31.692928    0  \n",
       "id00040   14.512740   10.095722    7.234862    1  \n",
       "id00042  131.193774  116.496717  117.210467    1  \n",
       "id00043   23.064022   19.682376   23.819299    0  \n",
       "id00044   18.242509   16.818772   17.791680    1  \n",
       "id00047   16.442029   30.591993   31.528857    1  \n",
       "id00049    9.018789    8.592075   10.045943    1  \n",
       "id00051  115.553566   62.789704  130.137807    1  \n",
       "id00052    7.245253    4.246504    4.010246    1  \n",
       "id00053   12.916443   16.294392   11.336656    1  \n",
       "id00055    2.112174    3.131860    2.405244    1  \n",
       "id00056    3.856813    8.135829    6.221934    1  \n",
       "id00058   23.609476   25.127126   26.966707    1  \n",
       "id00059   18.891045   25.606971   16.162705    1  \n",
       "id00060    8.961100   10.051687   15.596128    1  \n",
       "...             ...         ...         ...  ...  \n",
       "id09203    6.368062    7.663880    5.883139    0  \n",
       "id09204   25.305712   13.302571   36.935933    0  \n",
       "id09205    8.365533   10.352451    7.275319    0  \n",
       "id09207   10.125715   11.233365   12.249143    1  \n",
       "id09210   38.321410   49.467456   48.534160    1  \n",
       "id09211   42.937673   45.411177   90.820288    1  \n",
       "id09212    7.302669   10.972449    8.564203    1  \n",
       "id09213   33.117048   31.834561   39.096932    0  \n",
       "id09214   23.348284   17.976584   13.224837    1  \n",
       "id09215   34.023825   35.584575   35.359570    1  \n",
       "id09216   44.333512   20.904155   38.298939    0  \n",
       "id09218    3.469950    2.824201    2.898943    1  \n",
       "id09220   12.727123   11.075252   13.690630    1  \n",
       "id09222   21.679499   19.383145   29.803869    1  \n",
       "id09224    3.755238    4.002905    4.239678    1  \n",
       "id09225    3.585039    3.849685    3.259752    1  \n",
       "id09227   15.966737   24.321330    7.125147    1  \n",
       "id09230   17.613298   17.871577   16.711567    1  \n",
       "id09232   25.201281   22.084093   20.928128    0  \n",
       "id09234    6.263301    7.897838    9.624410    0  \n",
       "id09235   15.888872    7.825175   14.109119    1  \n",
       "id09236   23.019418   24.264499   30.028316    1  \n",
       "id09237   30.178227   32.311612   41.688222    1  \n",
       "id09242    3.428962    6.369811   11.240044    1  \n",
       "id09243    7.173589    5.972636    6.233966    1  \n",
       "id09245  140.373393  111.748909   91.277771    1  \n",
       "id09263   11.817848   21.894774   19.228095    1  \n",
       "id09268   18.133056   28.581963   10.892175    1  \n",
       "id09269   13.536814   10.799883   18.118513    1  \n",
       "id09272   60.163159   64.886583   49.516520    1  \n",
       "\n",
       "[4959 rows x 191 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mean_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_df = df_fft.groupby('ID').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=25\n",
    "pca = PCA(n_components=n)\n",
    "pca_X = pca.fit_transform(df_mean_3.iloc[:,:190])\n",
    "df_features_PCA = pd.DataFrame(pca_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.51026233, 0.13932259, 0.10366152, 0.06490736, 0.02737109,\n",
       "       0.01573507, 0.01401466, 0.00978887, 0.00650316, 0.00581508,\n",
       "       0.00428812, 0.00377912, 0.00355633, 0.00308771, 0.00281847,\n",
       "       0.00253464, 0.00228157, 0.00211445, 0.00210342, 0.00182728,\n",
       "       0.00165933, 0.0014891 , 0.00136591, 0.00132909, 0.00126089])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-40.76488929,  -8.25719132, -28.01153587, -12.69589374,\n",
       "         5.36717668,   7.2504284 ,  -3.80201438,  -6.44959764])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RangeIndex(start=0, stop=8, step=1)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_features_PCA.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "labels ['Unnamed: 0'] not contained in axis",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-b9521ca7e1e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_features_PCA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'Unnamed: 0'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Gender'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   2528\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2529\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2530\u001b[0;31m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2532\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[0;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[1;32m   2560\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2561\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2562\u001b[0;31m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2563\u001b[0m             \u001b[0mdropped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2564\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   3742\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'ignore'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3743\u001b[0m                 raise ValueError('labels %s not contained in axis' %\n\u001b[0;32m-> 3744\u001b[0;31m                                  labels[mask])\n\u001b[0m\u001b[1;32m   3745\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3746\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: labels ['Unnamed: 0'] not contained in axis"
     ]
    }
   ],
   "source": [
    "df_features_PCA.drop(columns = ['Unnamed: 0', 'Gender'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2346</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2347</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2348</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2349</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2350</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2351</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2352</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2353</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2354</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2355</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2356</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2357</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2358</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2359</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2360</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2361</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2362</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2363</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2364</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2365</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2366</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2367</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2368</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2369</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2370</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2371</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2372</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2373</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2374</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2375</th>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2376 rows × 0 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, ...]\n",
       "\n",
       "[2376 rows x 0 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_features_PCA.iloc[:,193:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_fft.iloc[:,:190]\n",
    "y = df_fft['Sex']\n",
    "# X = mean_df.iloc[:,:190]\n",
    "# X = df_mean_3.iloc[:,:190]\n",
    "# X = df_features_PCA\n",
    "# y = df_mean_3['Sex']\n",
    "X = scale(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3719, 3719)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train), len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7889433932881725, 0.7876478282922662, {'C': 0.1, 'penalty': 'l2'})"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_params = {'C': [ 1e-3, 1e-2, 1e-1],\n",
    "             'penalty': ['l1','l2']}\n",
    "log = GridSearchCV(LogisticRegression(), log_params, scoring='accuracy', cv = 3)\n",
    "log.fit(X_train,y_train)\n",
    "y_scorelog=log.predict_proba(X_test)[:,1]\n",
    "y_problog = log.predict_proba(X_test)\n",
    "coefficients = list(log.best_estimator_.coef_)\n",
    "fpr_log, tpr_log,_ = roc_curve(y_test, y_scorelog)\n",
    "roc_auc = auc(fpr_log, tpr_log)\n",
    "y_pred = log.predict(X_test)\n",
    "log.score(X_train, y_train), log.score(X_test, y_test), log.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.06956177, -0.20626183, -0.52687594, -0.18291282, -0.31321202,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.01864791,\n",
       "         0.        , -0.00417698,  0.        ,  0.        ,  0.        ,\n",
       "         0.03274496,  0.        ,  0.        ,  0.02358623,  0.01682659,\n",
       "         0.        ,  0.        ,  0.28321064,  0.        ,  0.16436758,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.16896546,\n",
       "        -0.06286249,  0.        ,  0.        ,  0.1718332 ,  0.45230231,\n",
       "         0.58049027,  0.25569078,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.42550119,  0.        ,  0.3041139 ,  0.        ,\n",
       "         0.10349014,  0.        ,  0.74874081,  0.        ,  0.5734857 ,\n",
       "        -0.0571005 ,  0.12770759,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.51246413,  0.67208259,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.33427148,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.26076578,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.03943853,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.00298822,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.10139617,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        -0.04590623,  0.        , -0.24575375,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        , -0.08259091,  0.        ,\n",
       "         0.        ,  0.        , -0.10176792,  0.        , -0.02335418,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        , -0.3684808 ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        , -0.21589548,  0.        ,  0.        ,  0.        ,\n",
       "         0.        , -0.13945862,  0.        , -0.14244938,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        -0.19148212,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "        -0.15790821,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log.best_estimator_.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df = metrics_df.append(pd.DataFrame(metrics_to_dict('Logistic Regression', y_test, y_pred, log.score(X_train, y_train), log.best_params_)).reset_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "chris_fft = pd.read_csv('Chris_fft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gradient boosting grid search\n",
    "gb_param = {'n_estimators' : [100,200],\n",
    "        'max_depth' : [1,2],\n",
    "        'learning_rate': [1e-2, 1e-1, 1]}\n",
    "gradboost = GridSearchCV(GradientBoostingClassifier(), gb_param,scoring = 'accuracy', cv= 2)\n",
    "gradboost.fit(X_train, y_train)\n",
    "y_score_gboost=gradboost.predict_proba(X_test)[:,1]\n",
    "y_prob_gboost = gradboost.predict_proba(X_test)\n",
    "fpr_gboost, tpr_gboost,_ = roc_curve(y_test, y_score_gboost)\n",
    "roc_auc = auc(fpr_gboost, tpr_gboost)\n",
    "y_pred_g = gradboost.predict(X_test)\n",
    "gradboost.score(X_train, y_train), gradboost.score(X_test, y_test), gradboost.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradboost.predict(chris_fft.iloc[:,1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df = metrics_df.append(pd.DataFrame(metrics_to_dict('Gradient Boosting w/ mean', y_test, y_pred_g, gradboost.score(X_train, y_train), gradboost.best_params_)).reset_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9152998117773595\n",
      "0.8693548387096774\n",
      "{'C': 1, 'degree': 2, 'kernel': 'rbf'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None, None)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_params ={'C' : [1e-1,1,1e1,11,12,13],\n",
    "        'kernel' : ['rbf','linear'],\n",
    "        'degree': [2,3]}\n",
    "svm = GridSearchCV(SVC(), svm_params, scoring= 'accuracy', cv=3)\n",
    "svm.fit(X_train, y_train)\n",
    "y_pred = svm.predict(X_test)\n",
    "print(svm.score(X_train, y_train)), print(svm.score(X_test, y_test)), print(svm.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df = metrics_df.append(pd.DataFrame(metrics_to_dict('SVM(PCA 25 w/mean 10)', y_test, y_pred, svm.score(X_train, y_train), svm.best_params_)).reset_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Hold Out Accuracy</th>\n",
       "      <th>Parameters</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Train Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Gradient Boosting w/ mean</td>\n",
       "      <td>0.940239</td>\n",
       "      <td>0.927419</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 2, 'n_esti...</td>\n",
       "      <td>0.945260</td>\n",
       "      <td>0.935271</td>\n",
       "      <td>0.983329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Logistic Regression mean</td>\n",
       "      <td>0.920027</td>\n",
       "      <td>0.905645</td>\n",
       "      <td>{'C': 0.1, 'penalty': 'l2'}</td>\n",
       "      <td>0.953258</td>\n",
       "      <td>0.889036</td>\n",
       "      <td>0.921753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Gradient Boosting w/ mean 25</td>\n",
       "      <td>0.915119</td>\n",
       "      <td>0.896774</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 2, 'n_esti...</td>\n",
       "      <td>0.918775</td>\n",
       "      <td>0.911493</td>\n",
       "      <td>0.973649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Logistic Regression mean 25</td>\n",
       "      <td>0.895522</td>\n",
       "      <td>0.875806</td>\n",
       "      <td>{'C': 0.1, 'penalty': 'l1'}</td>\n",
       "      <td>0.920502</td>\n",
       "      <td>0.871863</td>\n",
       "      <td>0.896209</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                     Algorithm  F1 Score  Hold Out Accuracy  \\\n",
       "0      0     Gradient Boosting w/ mean  0.940239           0.927419   \n",
       "0      0      Logistic Regression mean  0.920027           0.905645   \n",
       "0      0  Gradient Boosting w/ mean 25  0.915119           0.896774   \n",
       "0      0   Logistic Regression mean 25  0.895522           0.875806   \n",
       "\n",
       "                                          Parameters  Precision    Recall  \\\n",
       "0  {'learning_rate': 0.1, 'max_depth': 2, 'n_esti...   0.945260  0.935271   \n",
       "0                        {'C': 0.1, 'penalty': 'l2'}   0.953258  0.889036   \n",
       "0  {'learning_rate': 0.1, 'max_depth': 2, 'n_esti...   0.918775  0.911493   \n",
       "0                        {'C': 0.1, 'penalty': 'l1'}   0.920502  0.871863   \n",
       "\n",
       "   Train Accuracy  \n",
       "0        0.983329  \n",
       "0        0.921753  \n",
       "0        0.973649  \n",
       "0        0.896209  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_df.sort_values('Hold Out Accuracy', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level_0</th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Hold Out Accuracy</th>\n",
       "      <th>Parameters</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Logistic Regression(PCA w/ mean 7)</td>\n",
       "      <td>0.884097</td>\n",
       "      <td>0.855219</td>\n",
       "      <td>{'C': 0.1, 'penalty': 'l2'}</td>\n",
       "      <td>0.879357</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.840067</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Gradient Boosting(PCA w/ mean 7)</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>0.851852</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 1, 'n_esti...</td>\n",
       "      <td>0.870712</td>\n",
       "      <td>0.894309</td>\n",
       "      <td>0.850168</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>SVM(PCA w/mean 7)</td>\n",
       "      <td>0.891599</td>\n",
       "      <td>0.865320</td>\n",
       "      <td>{'C': 1, 'degree': 2, 'kernel': 'rbf'}</td>\n",
       "      <td>0.891599</td>\n",
       "      <td>0.891599</td>\n",
       "      <td>0.855219</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Logistic Regression(PCA w/ mean all)</td>\n",
       "      <td>0.935528</td>\n",
       "      <td>0.920875</td>\n",
       "      <td>{'C': 0.1, 'penalty': 'l2'}</td>\n",
       "      <td>0.947222</td>\n",
       "      <td>0.924119</td>\n",
       "      <td>0.915825</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Gradient Boosting(PCA w/ mean all)</td>\n",
       "      <td>0.942127</td>\n",
       "      <td>0.927609</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 2, 'n_esti...</td>\n",
       "      <td>0.935829</td>\n",
       "      <td>0.948509</td>\n",
       "      <td>0.932099</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>SVM(PCA w/mean all)</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.927609</td>\n",
       "      <td>{'C': 1, 'degree': 2, 'kernel': 'rbf'}</td>\n",
       "      <td>0.950276</td>\n",
       "      <td>0.932249</td>\n",
       "      <td>0.934343</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>Logistic Regression(mean all)</td>\n",
       "      <td>0.947945</td>\n",
       "      <td>0.936027</td>\n",
       "      <td>{'C': 0.1, 'penalty': 'l2'}</td>\n",
       "      <td>0.958449</td>\n",
       "      <td>0.937669</td>\n",
       "      <td>0.941077</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9</td>\n",
       "      <td>Logistic Regression(mean 7)</td>\n",
       "      <td>0.895238</td>\n",
       "      <td>0.870370</td>\n",
       "      <td>{'C': 0.1, 'penalty': 'l2'}</td>\n",
       "      <td>0.898907</td>\n",
       "      <td>0.891599</td>\n",
       "      <td>0.869248</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10</td>\n",
       "      <td>Gradient Boosting(mean 7)</td>\n",
       "      <td>0.912234</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 2, 'n_esti...</td>\n",
       "      <td>0.895561</td>\n",
       "      <td>0.929539</td>\n",
       "      <td>0.916386</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>Logistic Regression(mean 3)</td>\n",
       "      <td>0.866035</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>{'C': 0.1, 'penalty': 'l1'}</td>\n",
       "      <td>0.864865</td>\n",
       "      <td>0.867209</td>\n",
       "      <td>0.840629</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>Gradient Boosting(mean 3)</td>\n",
       "      <td>0.864652</td>\n",
       "      <td>0.826599</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 1, 'n_esti...</td>\n",
       "      <td>0.839286</td>\n",
       "      <td>0.891599</td>\n",
       "      <td>0.873176</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>Logistic Regression(mean 10)</td>\n",
       "      <td>0.901639</td>\n",
       "      <td>0.878788</td>\n",
       "      <td>{'C': 0.1, 'penalty': 'l1'}</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.894309</td>\n",
       "      <td>0.867003</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    level_0                             Algorithm  F1 Score  \\\n",
       "0         0    Logistic Regression(PCA w/ mean 7)  0.884097   \n",
       "1         1      Gradient Boosting(PCA w/ mean 7)  0.882353   \n",
       "2         2                     SVM(PCA w/mean 7)  0.891599   \n",
       "3         3  Logistic Regression(PCA w/ mean all)  0.935528   \n",
       "4         4    Gradient Boosting(PCA w/ mean all)  0.942127   \n",
       "5         5                   SVM(PCA w/mean all)  0.941176   \n",
       "6         6         Logistic Regression(mean all)  0.947945   \n",
       "7         9           Logistic Regression(mean 7)  0.895238   \n",
       "8        10             Gradient Boosting(mean 7)  0.912234   \n",
       "9         0           Logistic Regression(mean 3)  0.866035   \n",
       "10        0             Gradient Boosting(mean 3)  0.864652   \n",
       "11        0          Logistic Regression(mean 10)  0.901639   \n",
       "\n",
       "    Hold Out Accuracy                                         Parameters  \\\n",
       "0            0.855219                        {'C': 0.1, 'penalty': 'l2'}   \n",
       "1            0.851852  {'learning_rate': 0.1, 'max_depth': 1, 'n_esti...   \n",
       "2            0.865320             {'C': 1, 'degree': 2, 'kernel': 'rbf'}   \n",
       "3            0.920875                        {'C': 0.1, 'penalty': 'l2'}   \n",
       "4            0.927609  {'learning_rate': 0.1, 'max_depth': 2, 'n_esti...   \n",
       "5            0.927609             {'C': 1, 'degree': 2, 'kernel': 'rbf'}   \n",
       "6            0.936027                        {'C': 0.1, 'penalty': 'l2'}   \n",
       "7            0.870370                        {'C': 0.1, 'penalty': 'l2'}   \n",
       "8            0.888889  {'learning_rate': 0.1, 'max_depth': 2, 'n_esti...   \n",
       "9            0.833333                        {'C': 0.1, 'penalty': 'l1'}   \n",
       "10           0.826599  {'learning_rate': 0.1, 'max_depth': 1, 'n_esti...   \n",
       "11           0.878788                        {'C': 0.1, 'penalty': 'l1'}   \n",
       "\n",
       "    Precision    Recall  Train Accuracy  index  \n",
       "0    0.879357  0.888889        0.840067      0  \n",
       "1    0.870712  0.894309        0.850168      0  \n",
       "2    0.891599  0.891599        0.855219      0  \n",
       "3    0.947222  0.924119        0.915825      0  \n",
       "4    0.935829  0.948509        0.932099      0  \n",
       "5    0.950276  0.932249        0.934343      0  \n",
       "6    0.958449  0.937669        0.941077      0  \n",
       "7    0.898907  0.891599        0.869248      0  \n",
       "8    0.895561  0.929539        0.916386      0  \n",
       "9    0.864865  0.867209        0.840629      0  \n",
       "10   0.839286  0.891599        0.873176      0  \n",
       "11   0.909091  0.894309        0.867003      0  "
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_df.drop(index=[12], inplace=True)\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df.to_csv('Modeling_Results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-161-8b97cad38604>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m         'learning_rate': [1e-2, 1e-1, 1]}\n\u001b[1;32m      4\u001b[0m \u001b[0mxgb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXGBClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxgb_param\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mxgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    637\u001b[0m                                   error_score=self.error_score)\n\u001b[1;32m    638\u001b[0m           for parameters, (train, test) in product(candidate_params,\n\u001b[0;32m--> 639\u001b[0;31m                                                    cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m         \u001b[0;31m# if one choose to see train score, \"out\" will contain train score info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    777\u001b[0m             \u001b[0;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    623\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 588\u001b[0;31m         \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, error_score)\u001b[0m\n\u001b[1;32m    456\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set)\u001b[0m\n\u001b[1;32m    545\u001b[0m                               \u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m                               \u001b[0mevals_result\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m                               verbose_eval=verbose, xgb_model=None)\n\u001b[0m\u001b[1;32m    548\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjective\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb_options\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"objective\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, learning_rates)\u001b[0m\n\u001b[1;32m    202\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mversion\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1019\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1020\u001b[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle, ctypes.c_int(iteration),\n\u001b[0;32m-> 1021\u001b[0;31m                                                     dtrain.handle))\n\u001b[0m\u001b[1;32m   1022\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "xgb_param = {'n_estimators' : [100,200,300],\n",
    "        'max_depth' : [1,2,3,5],\n",
    "        'learning_rate': [1e-2, 1e-1, 1]}\n",
    "xgb = GridSearchCV(XGBClassifier(), xgb_param, cv=3)\n",
    "xgb.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=1, min_child_weight=1, missing=None, n_estimators=380,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb = XGBClassifier(max_depth=1,learning_rate=0.1,n_estimators=380)\n",
    "xgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "y_pred_xgb = xgb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py:6211: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  sort=sort)\n"
     ]
    }
   ],
   "source": [
    "metrics_df = metrics_df.append(pd.DataFrame(metrics_to_dict('XGBoost(PCA+8Features)', y_test, y_pred_xgb, xgb.score(X_train, y_train), 'None')).reset_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_metrics = pd.read_csv('modeling_results_2')\n",
    "older_metrics = pd.read_csv('Modeling_Results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_metrics = old_metrics.append(metrics_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>index</th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Hold Out Accuracy</th>\n",
       "      <th>Parameters</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Train Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Gradient Boosting mean all</td>\n",
       "      <td>0.940239</td>\n",
       "      <td>0.927419</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 2, 'n_esti...</td>\n",
       "      <td>0.945260</td>\n",
       "      <td>0.935271</td>\n",
       "      <td>0.983329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Gradient Boosting w/ PCA mean all</td>\n",
       "      <td>0.940239</td>\n",
       "      <td>0.927419</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 2, 'n_esti...</td>\n",
       "      <td>0.945260</td>\n",
       "      <td>0.935271</td>\n",
       "      <td>0.983329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SVM(PCA w/mean all)</td>\n",
       "      <td>0.933956</td>\n",
       "      <td>0.920161</td>\n",
       "      <td>{'C': 10.0, 'degree': 2, 'kernel': 'rbf'}</td>\n",
       "      <td>0.943396</td>\n",
       "      <td>0.924703</td>\n",
       "      <td>0.957247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Gradient Boosting w/ PCA mean all</td>\n",
       "      <td>0.930201</td>\n",
       "      <td>0.916129</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 2, 'n_esti...</td>\n",
       "      <td>0.945430</td>\n",
       "      <td>0.915456</td>\n",
       "      <td>0.962624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Logistic Regression Mean all</td>\n",
       "      <td>0.920027</td>\n",
       "      <td>0.905645</td>\n",
       "      <td>{'C': 0.1, 'penalty': 'l2'}</td>\n",
       "      <td>0.953258</td>\n",
       "      <td>0.889036</td>\n",
       "      <td>0.921753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Logistic Regression PCA w/ Mean all</td>\n",
       "      <td>0.913781</td>\n",
       "      <td>0.897581</td>\n",
       "      <td>{'C': 0.01, 'penalty': 'l2'}</td>\n",
       "      <td>0.939944</td>\n",
       "      <td>0.889036</td>\n",
       "      <td>0.908040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Gradient Boosting mean 25</td>\n",
       "      <td>0.915119</td>\n",
       "      <td>0.896774</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 2, 'n_esti...</td>\n",
       "      <td>0.918775</td>\n",
       "      <td>0.911493</td>\n",
       "      <td>0.973649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Gradient Boosting mean 10</td>\n",
       "      <td>0.909809</td>\n",
       "      <td>0.889516</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 2, 'n_esti...</td>\n",
       "      <td>0.906824</td>\n",
       "      <td>0.912814</td>\n",
       "      <td>0.947298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Logistic Regression Mean 25</td>\n",
       "      <td>0.895522</td>\n",
       "      <td>0.875806</td>\n",
       "      <td>{'C': 0.1, 'penalty': 'l1'}</td>\n",
       "      <td>0.920502</td>\n",
       "      <td>0.871863</td>\n",
       "      <td>0.895940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Gradient Boosting w/ PCA mean 10</td>\n",
       "      <td>0.897470</td>\n",
       "      <td>0.875806</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 2, 'n_esti...</td>\n",
       "      <td>0.904698</td>\n",
       "      <td>0.890357</td>\n",
       "      <td>0.917451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SVM(PCA w/mean 10)</td>\n",
       "      <td>0.894560</td>\n",
       "      <td>0.873387</td>\n",
       "      <td>{'C': 10.0, 'degree': 2, 'kernel': 'rbf'}</td>\n",
       "      <td>0.909836</td>\n",
       "      <td>0.879789</td>\n",
       "      <td>0.917989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Gradient Boosting w/ PCA(25) mean 10</td>\n",
       "      <td>0.893929</td>\n",
       "      <td>0.871774</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 2, 'n_esti...</td>\n",
       "      <td>0.902965</td>\n",
       "      <td>0.885073</td>\n",
       "      <td>0.927938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SVM(PCA 25 w/mean 10)</td>\n",
       "      <td>0.892715</td>\n",
       "      <td>0.869355</td>\n",
       "      <td>{'C': 1, 'degree': 2, 'kernel': 'rbf'}</td>\n",
       "      <td>0.895086</td>\n",
       "      <td>0.890357</td>\n",
       "      <td>0.915300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Logistic Regression PCA w/ Mean all</td>\n",
       "      <td>0.884511</td>\n",
       "      <td>0.862903</td>\n",
       "      <td>{'C': 0.1, 'penalty': 'l2'}</td>\n",
       "      <td>0.910490</td>\n",
       "      <td>0.859974</td>\n",
       "      <td>0.866362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Logistic Regression Mean 10</td>\n",
       "      <td>0.883910</td>\n",
       "      <td>0.862097</td>\n",
       "      <td>{'C': 0.1, 'penalty': 'l1'}</td>\n",
       "      <td>0.909218</td>\n",
       "      <td>0.859974</td>\n",
       "      <td>0.883571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Gradient Boosting mean 3</td>\n",
       "      <td>0.878431</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 2, 'n_esti...</td>\n",
       "      <td>0.869340</td>\n",
       "      <td>0.887715</td>\n",
       "      <td>0.934660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Logistic Regression Mean 3</td>\n",
       "      <td>0.865895</td>\n",
       "      <td>0.841129</td>\n",
       "      <td>{'C': 0.1, 'penalty': 'l1'}</td>\n",
       "      <td>0.893258</td>\n",
       "      <td>0.840159</td>\n",
       "      <td>0.855069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Gradient Boosting mean 3</td>\n",
       "      <td>0.861598</td>\n",
       "      <td>0.828226</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 2, 'n_esti...</td>\n",
       "      <td>0.847826</td>\n",
       "      <td>0.875826</td>\n",
       "      <td>0.907233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Logistic Regression Mean 3</td>\n",
       "      <td>0.854632</td>\n",
       "      <td>0.826613</td>\n",
       "      <td>{'C': 0.1, 'penalty': 'l1'}</td>\n",
       "      <td>0.875346</td>\n",
       "      <td>0.834875</td>\n",
       "      <td>0.838397</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0  index                             Algorithm  F1 Score  \\\n",
       "0            0      0            Gradient Boosting mean all  0.940239   \n",
       "1            0      0     Gradient Boosting w/ PCA mean all  0.940239   \n",
       "2            0      0                   SVM(PCA w/mean all)  0.933956   \n",
       "3            0      0     Gradient Boosting w/ PCA mean all  0.930201   \n",
       "4            0      0          Logistic Regression Mean all  0.920027   \n",
       "5            0      0   Logistic Regression PCA w/ Mean all  0.913781   \n",
       "6            0      0             Gradient Boosting mean 25  0.915119   \n",
       "7            0      0             Gradient Boosting mean 10  0.909809   \n",
       "9            0      0           Logistic Regression Mean 25  0.895522   \n",
       "8            0      0      Gradient Boosting w/ PCA mean 10  0.897470   \n",
       "10           0      0                    SVM(PCA w/mean 10)  0.894560   \n",
       "11           0      0  Gradient Boosting w/ PCA(25) mean 10  0.893929   \n",
       "12           0      0                 SVM(PCA 25 w/mean 10)  0.892715   \n",
       "13           0      0   Logistic Regression PCA w/ Mean all  0.884511   \n",
       "14           0      0           Logistic Regression Mean 10  0.883910   \n",
       "15           0      0              Gradient Boosting mean 3  0.878431   \n",
       "16           0      0            Logistic Regression Mean 3  0.865895   \n",
       "17           0      0              Gradient Boosting mean 3  0.861598   \n",
       "18           0      0            Logistic Regression Mean 3  0.854632   \n",
       "\n",
       "    Hold Out Accuracy                                         Parameters  \\\n",
       "0            0.927419  {'learning_rate': 0.1, 'max_depth': 2, 'n_esti...   \n",
       "1            0.927419  {'learning_rate': 0.1, 'max_depth': 2, 'n_esti...   \n",
       "2            0.920161          {'C': 10.0, 'degree': 2, 'kernel': 'rbf'}   \n",
       "3            0.916129  {'learning_rate': 0.1, 'max_depth': 2, 'n_esti...   \n",
       "4            0.905645                        {'C': 0.1, 'penalty': 'l2'}   \n",
       "5            0.897581                       {'C': 0.01, 'penalty': 'l2'}   \n",
       "6            0.896774  {'learning_rate': 0.1, 'max_depth': 2, 'n_esti...   \n",
       "7            0.889516  {'learning_rate': 0.1, 'max_depth': 2, 'n_esti...   \n",
       "9            0.875806                        {'C': 0.1, 'penalty': 'l1'}   \n",
       "8            0.875806  {'learning_rate': 0.1, 'max_depth': 2, 'n_esti...   \n",
       "10           0.873387          {'C': 10.0, 'degree': 2, 'kernel': 'rbf'}   \n",
       "11           0.871774  {'learning_rate': 0.1, 'max_depth': 2, 'n_esti...   \n",
       "12           0.869355             {'C': 1, 'degree': 2, 'kernel': 'rbf'}   \n",
       "13           0.862903                        {'C': 0.1, 'penalty': 'l2'}   \n",
       "14           0.862097                        {'C': 0.1, 'penalty': 'l1'}   \n",
       "15           0.850000  {'learning_rate': 0.1, 'max_depth': 2, 'n_esti...   \n",
       "16           0.841129                        {'C': 0.1, 'penalty': 'l1'}   \n",
       "17           0.828226  {'learning_rate': 0.1, 'max_depth': 2, 'n_esti...   \n",
       "18           0.826613                        {'C': 0.1, 'penalty': 'l1'}   \n",
       "\n",
       "    Precision    Recall  Train Accuracy  \n",
       "0    0.945260  0.935271        0.983329  \n",
       "1    0.945260  0.935271        0.983329  \n",
       "2    0.943396  0.924703        0.957247  \n",
       "3    0.945430  0.915456        0.962624  \n",
       "4    0.953258  0.889036        0.921753  \n",
       "5    0.939944  0.889036        0.908040  \n",
       "6    0.918775  0.911493        0.973649  \n",
       "7    0.906824  0.912814        0.947298  \n",
       "9    0.920502  0.871863        0.895940  \n",
       "8    0.904698  0.890357        0.917451  \n",
       "10   0.909836  0.879789        0.917989  \n",
       "11   0.902965  0.885073        0.927938  \n",
       "12   0.895086  0.890357        0.915300  \n",
       "13   0.910490  0.859974        0.866362  \n",
       "14   0.909218  0.859974        0.883571  \n",
       "15   0.869340  0.887715        0.934660  \n",
       "16   0.893258  0.840159        0.855069  \n",
       "17   0.847826  0.875826        0.907233  \n",
       "18   0.875346  0.834875        0.838397  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_metrics.sort_values('Hold Out Accuracy', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Hold Out Accuracy</th>\n",
       "      <th>Parameters</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>index</th>\n",
       "      <th>level_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>Logistic Regression(mean all)</td>\n",
       "      <td>0.947945</td>\n",
       "      <td>0.936027</td>\n",
       "      <td>{'C': 0.1, 'penalty': 'l2'}</td>\n",
       "      <td>0.958449</td>\n",
       "      <td>0.937669</td>\n",
       "      <td>0.941077</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Gradient Boosting(PCA w/ mean all)</td>\n",
       "      <td>0.942127</td>\n",
       "      <td>0.927609</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 2, 'n_esti...</td>\n",
       "      <td>0.935829</td>\n",
       "      <td>0.948509</td>\n",
       "      <td>0.932099</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>SVM(PCA w/mean all)</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.927609</td>\n",
       "      <td>{'C': 1, 'degree': 2, 'kernel': 'rbf'}</td>\n",
       "      <td>0.950276</td>\n",
       "      <td>0.932249</td>\n",
       "      <td>0.934343</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Logistic Regression(PCA w/ mean all)</td>\n",
       "      <td>0.935528</td>\n",
       "      <td>0.920875</td>\n",
       "      <td>{'C': 0.1, 'penalty': 'l2'}</td>\n",
       "      <td>0.947222</td>\n",
       "      <td>0.924119</td>\n",
       "      <td>0.915825</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>Gradient Boosting(mean 15)</td>\n",
       "      <td>0.921647</td>\n",
       "      <td>0.900673</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 2, 'n_esti...</td>\n",
       "      <td>0.903646</td>\n",
       "      <td>0.940379</td>\n",
       "      <td>0.961279</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>Gradient Boosting(mean 7)</td>\n",
       "      <td>0.912234</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 2, 'n_esti...</td>\n",
       "      <td>0.895561</td>\n",
       "      <td>0.929539</td>\n",
       "      <td>0.916386</td>\n",
       "      <td>0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>Gradient Boosting(mean 10)</td>\n",
       "      <td>0.911258</td>\n",
       "      <td>0.887205</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 2, 'n_esti...</td>\n",
       "      <td>0.891192</td>\n",
       "      <td>0.932249</td>\n",
       "      <td>0.978114</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>Logistic Regression(mean 15)</td>\n",
       "      <td>0.907357</td>\n",
       "      <td>0.885522</td>\n",
       "      <td>{'C': 0.1, 'penalty': 'l1'}</td>\n",
       "      <td>0.912329</td>\n",
       "      <td>0.902439</td>\n",
       "      <td>0.868126</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>Logistic Regression(mean 10)</td>\n",
       "      <td>0.901639</td>\n",
       "      <td>0.878788</td>\n",
       "      <td>{'C': 0.1, 'penalty': 'l1'}</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.894309</td>\n",
       "      <td>0.867003</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>Logistic Regression(mean 7)</td>\n",
       "      <td>0.895238</td>\n",
       "      <td>0.870370</td>\n",
       "      <td>{'C': 0.1, 'penalty': 'l2'}</td>\n",
       "      <td>0.898907</td>\n",
       "      <td>0.891599</td>\n",
       "      <td>0.869248</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>SVM(PCA w/mean 7)</td>\n",
       "      <td>0.891599</td>\n",
       "      <td>0.865320</td>\n",
       "      <td>{'C': 1, 'degree': 2, 'kernel': 'rbf'}</td>\n",
       "      <td>0.891599</td>\n",
       "      <td>0.891599</td>\n",
       "      <td>0.855219</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Logistic Regression(PCA w/ mean 7)</td>\n",
       "      <td>0.884097</td>\n",
       "      <td>0.855219</td>\n",
       "      <td>{'C': 0.1, 'penalty': 'l2'}</td>\n",
       "      <td>0.879357</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.840067</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Gradient Boosting(PCA w/ mean 7)</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>0.851852</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 1, 'n_esti...</td>\n",
       "      <td>0.870712</td>\n",
       "      <td>0.894309</td>\n",
       "      <td>0.850168</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>Logistic Regression(mean 3)</td>\n",
       "      <td>0.866035</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>{'C': 0.1, 'penalty': 'l1'}</td>\n",
       "      <td>0.864865</td>\n",
       "      <td>0.867209</td>\n",
       "      <td>0.840629</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>Gradient Boosting(mean 3)</td>\n",
       "      <td>0.864652</td>\n",
       "      <td>0.826599</td>\n",
       "      <td>{'learning_rate': 0.1, 'max_depth': 1, 'n_esti...</td>\n",
       "      <td>0.839286</td>\n",
       "      <td>0.891599</td>\n",
       "      <td>0.873176</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0                             Algorithm  F1 Score  \\\n",
       "6            6         Logistic Regression(mean all)  0.947945   \n",
       "4            4    Gradient Boosting(PCA w/ mean all)  0.942127   \n",
       "5            5                   SVM(PCA w/mean all)  0.941176   \n",
       "3            3  Logistic Regression(PCA w/ mean all)  0.935528   \n",
       "14           0            Gradient Boosting(mean 15)  0.921647   \n",
       "8            8             Gradient Boosting(mean 7)  0.912234   \n",
       "12           0            Gradient Boosting(mean 10)  0.911258   \n",
       "13           0          Logistic Regression(mean 15)  0.907357   \n",
       "11          11          Logistic Regression(mean 10)  0.901639   \n",
       "7            7           Logistic Regression(mean 7)  0.895238   \n",
       "2            2                     SVM(PCA w/mean 7)  0.891599   \n",
       "0            0    Logistic Regression(PCA w/ mean 7)  0.884097   \n",
       "1            1      Gradient Boosting(PCA w/ mean 7)  0.882353   \n",
       "9            9           Logistic Regression(mean 3)  0.866035   \n",
       "10          10             Gradient Boosting(mean 3)  0.864652   \n",
       "\n",
       "    Hold Out Accuracy                                         Parameters  \\\n",
       "6            0.936027                        {'C': 0.1, 'penalty': 'l2'}   \n",
       "4            0.927609  {'learning_rate': 0.1, 'max_depth': 2, 'n_esti...   \n",
       "5            0.927609             {'C': 1, 'degree': 2, 'kernel': 'rbf'}   \n",
       "3            0.920875                        {'C': 0.1, 'penalty': 'l2'}   \n",
       "14           0.900673  {'learning_rate': 0.1, 'max_depth': 2, 'n_esti...   \n",
       "8            0.888889  {'learning_rate': 0.1, 'max_depth': 2, 'n_esti...   \n",
       "12           0.887205  {'learning_rate': 0.1, 'max_depth': 2, 'n_esti...   \n",
       "13           0.885522                        {'C': 0.1, 'penalty': 'l1'}   \n",
       "11           0.878788                        {'C': 0.1, 'penalty': 'l1'}   \n",
       "7            0.870370                        {'C': 0.1, 'penalty': 'l2'}   \n",
       "2            0.865320             {'C': 1, 'degree': 2, 'kernel': 'rbf'}   \n",
       "0            0.855219                        {'C': 0.1, 'penalty': 'l2'}   \n",
       "1            0.851852  {'learning_rate': 0.1, 'max_depth': 1, 'n_esti...   \n",
       "9            0.833333                        {'C': 0.1, 'penalty': 'l1'}   \n",
       "10           0.826599  {'learning_rate': 0.1, 'max_depth': 1, 'n_esti...   \n",
       "\n",
       "    Precision    Recall  Train Accuracy  index  level_0  \n",
       "6    0.958449  0.937669        0.941077      0      6.0  \n",
       "4    0.935829  0.948509        0.932099      0      4.0  \n",
       "5    0.950276  0.932249        0.934343      0      5.0  \n",
       "3    0.947222  0.924119        0.915825      0      3.0  \n",
       "14   0.903646  0.940379        0.961279      0      NaN  \n",
       "8    0.895561  0.929539        0.916386      0     10.0  \n",
       "12   0.891192  0.932249        0.978114      0      NaN  \n",
       "13   0.912329  0.902439        0.868126      0      NaN  \n",
       "11   0.909091  0.894309        0.867003      0      0.0  \n",
       "7    0.898907  0.891599        0.869248      0      9.0  \n",
       "2    0.891599  0.891599        0.855219      0      2.0  \n",
       "0    0.879357  0.888889        0.840067      0      0.0  \n",
       "1    0.870712  0.894309        0.850168      0      1.0  \n",
       "9    0.864865  0.867209        0.840629      0      0.0  \n",
       "10   0.839286  0.891599        0.873176      0      0.0  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "older_metrics.sort_values('Hold Out Accuracy', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_metrics.to_csv('modeling_results_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
